globalThis.process ??= {}; globalThis.process.env ??= {};
const _astro_dataLayerContent = [["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.7.13","content-config-digest","11fd0975a9fac139","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://dev.opencode.ai\",\"compressHTML\":true,\"base\":\"/docs\",\"trailingSlash\":\"ignore\",\"output\":\"server\",\"scopedStyleStrategy\":\"where\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"index.js\",\"redirects\":false,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":\"0.0.0.0\",\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{\"/discord\":\"https://discord.gg/opencode\"},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/noop\",\"config\":{}},\"domains\":[],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":false},\"markdown\":{\"syntaxHighlight\":false,\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[null,[null,{\"behavior\":\"wrap\"}],null,[null,{\"themes\":[\"github-light\",\"github-dark\"],\"defaultLocale\":\"en\",\"cascadeLayer\":\"starlight.components\",\"styleOverrides\":{\"borderRadius\":\"0px\",\"borderWidth\":\"1px\",\"codePaddingBlock\":\"0.75rem\",\"codePaddingInline\":\"1rem\",\"codeFontFamily\":\"var(--__sl-font-mono)\",\"codeFontSize\":\"var(--sl-text-code)\",\"codeLineHeight\":\"var(--sl-line-height)\",\"uiFontFamily\":\"var(--__sl-font)\",\"textMarkers\":{\"lineDiffIndicatorMarginLeft\":\"0.25rem\",\"defaultChroma\":\"45\",\"backgroundOpacity\":\"60%\"}},\"plugins\":[{\"name\":\"Starlight Plugin\",\"hooks\":{}},{\"name\":\"astro-expressive-code\",\"hooks\":{}}]}]],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false},\"legacy\":{\"collections\":false},\"session\":{\"driver\":\"cloudflare-kv-binding\",\"options\":{\"binding\":\"SESSION\"}},\"prefetch\":{\"prefetchAll\":true},\"i18n\":{\"defaultLocale\":\"en\",\"locales\":[\"en\"],\"routing\":{\"prefixDefaultLocale\":false,\"redirectToDefaultLocale\":false,\"fallbackType\":\"redirect\"}}}","docs",["Map",11,12,25,26,36,37,47,48,58,59,69,70,80,81,91,92,102,103,113,114,124,125,135,136,146,147,157,158,168,169,179,180,190,191,201,202,212,213,223,224,234,235,245,246,256,257,267,268,278,279,289,290,300,301,311,312],"agents",{id:11,data:13,body:22,filePath:23,digest:24,deferredRender:16},{title:14,description:15,editUrl:16,head:17,template:18,sidebar:19,pagefind:16,draft:20},"Agents","Configure and use specialized agents.",true,[],"doc",{hidden:20,attrs:21},false,{},"Agents are specialized AI assistants that can be configured for specific tasks and workflows. They allow you to create focused tools with custom prompts, models, and tool access.\n\n:::tip\nUse the plan agent to analyze code and review suggestions without making any code changes.\n:::\n\nYou can switch between agents during a session or invoke them with the `@` mention.\n\n---\n\n## Types\n\nThere are two types of agents in OpenCode; primary agents and subagents.\n\n---\n\n### Primary agents\n\nPrimary agents are the main assistants you interact with directly. You can cycle through them using the **Tab** key, or your configured `switch_agent` keybind. These agents handle your main conversation and can access all configured tools.\n\n:::tip\nYou can use the **Tab** key to switch between primary agents during a session.\n:::\n\nOpenCode comes with two built-in primary agents, **Build** and **Plan**. We'll\nlook at these below.\n\n---\n\n### Subagents\n\nSubagents are specialized assistants that primary agents can invoke for specific tasks. You can also manually invoke them by **@ mentioning** them in your messages.\n\nOpenCode comes with one built-in subagent, **General**. We'll look at this below.\n\n---\n\n## Built-in\n\nOpenCode comes with two built-in primary agents and one built-in subagent.\n\n---\n\n### Build\n\n_Mode_: `primary`\n\nBuild is the **default** primary agent with all tools enabled. This is the standard agent for development work where you need full access to file operations and system commands.\n\n---\n\n### Plan\n\n_Mode_: `primary`\n\nA restricted agent designed for planning and analysis. We use a permission system to give you more control and prevent unintended changes.\nBy default, all of the following are set to `ask`:\n\n- `file edits`: All writes, patches, and edits\n- `bash`: All bash commands\n\nThis agent is useful when you want the LLM to analyze code, suggest changes, or create plans without making any actual modifications to your codebase.\n\n---\n\n### General\n\n_Mode_: `subagent`\n\nA general-purpose agent for researching complex questions, searching for code, and executing multi-step tasks. Use when searching for keywords or files and you're not confident you'll find the right match in the first few tries.\n\n---\n\n## Usage\n\n1. For primary agents, use the **Tab** key to cycle through them during a session. You can also use your configured `switch_agent` keybind.\n\n2. Subagents can be invoked:\n   - **Automatically** by primary agents for specialized tasks based on their descriptions.\n   - Manually by **@ mentioning** a subagent in your message. For example.\n\n     ```txt frame=\"none\"\n     @general help me search for this function\n     ```\n\n3. **Navigation between sessions**: When subagents create their own child sessions, you can navigate between the parent session and all child sessions using:\n   - **Ctrl+Right** (or your configured `session_child_cycle` keybind) to cycle forward through parent → child1 → child2 → ... → parent\n   - **Ctrl+Left** (or your configured `session_child_cycle_reverse` keybind) to cycle backward through parent ← child1 ← child2 ← ... ← parent\n\n   This allows you to seamlessly switch between the main conversation and specialized subagent work.\n\n---\n\n## Configure\n\nYou can customize the built-in agents or create your own through configuration. Agents can be configured in two ways:\n\n---\n\n### JSON\n\nConfigure agents in your `opencode.json` config file:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"build\": {\n      \"mode\": \"primary\",\n      \"model\": \"anthropic/claude-sonnet-4-20250514\",\n      \"prompt\": \"{file:./prompts/build.txt}\",\n      \"tools\": {\n        \"write\": true,\n        \"edit\": true,\n        \"bash\": true\n      }\n    },\n    \"plan\": {\n      \"mode\": \"primary\",\n      \"model\": \"anthropic/claude-haiku-4-20250514\",\n      \"tools\": {\n        \"write\": false,\n        \"edit\": false,\n        \"bash\": false\n      }\n    },\n    \"code-reviewer\": {\n      \"description\": \"Reviews code for best practices and potential issues\",\n      \"mode\": \"subagent\",\n      \"model\": \"anthropic/claude-sonnet-4-20250514\",\n      \"prompt\": \"You are a code reviewer. Focus on security, performance, and maintainability.\",\n      \"tools\": {\n        \"write\": false,\n        \"edit\": false\n      }\n    }\n  }\n}\n```\n\n---\n\n### Markdown\n\nYou can also define agents using markdown files. Place them in:\n\n- Global: `~/.config/opencode/agent/`\n- Per-project: `.opencode/agent/`\n\n```markdown title=\"~/.config/opencode/agent/review.md\"\n---\ndescription: Reviews code for quality and best practices\nmode: subagent\nmodel: anthropic/claude-sonnet-4-20250514\ntemperature: 0.1\ntools:\n  write: false\n  edit: false\n  bash: false\n---\n\nYou are in code review mode. Focus on:\n\n- Code quality and best practices\n- Potential bugs and edge cases\n- Performance implications\n- Security considerations\n\nProvide constructive feedback without making direct changes.\n```\n\nThe markdown file name becomes the agent name. For example, `review.md` creates a `review` agent.\n\n---\n\n## Options\n\nLet's look at these configuration options in detail.\n\n---\n\n### Description\n\nUse the `description` option to provide a brief description of what the agent does and when to use it.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"review\": {\n      \"description\": \"Reviews code for best practices and potential issues\"\n    }\n  }\n}\n```\n\nThis is a **required** config option.\n\n---\n\n### Temperature\n\nControl the randomness and creativity of the LLM's responses with the `temperature` config.\n\nLower values make responses more focused and deterministic, while higher values increase creativity and variability.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"plan\": {\n      \"temperature\": 0.1\n    },\n    \"creative\": {\n      \"temperature\": 0.8\n    }\n  }\n}\n```\n\nTemperature values typically range from 0.0 to 1.0:\n\n- **0.0-0.2**: Very focused and deterministic responses, ideal for code analysis and planning\n- **0.3-0.5**: Balanced responses with some creativity, good for general development tasks\n- **0.6-1.0**: More creative and varied responses, useful for brainstorming and exploration\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"analyze\": {\n      \"temperature\": 0.1,\n      \"prompt\": \"{file:./prompts/analysis.txt}\"\n    },\n    \"build\": {\n      \"temperature\": 0.3\n    },\n    \"brainstorm\": {\n      \"temperature\": 0.7,\n      \"prompt\": \"{file:./prompts/creative.txt}\"\n    }\n  }\n}\n```\n\nIf no temperature is specified, OpenCode uses model-specific defaults; typically 0 for most models, 0.55 for Qwen models.\n\n---\n\n### Disable\n\nSet to `true` to disable the agent.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"review\": {\n      \"disable\": true\n    }\n  }\n}\n```\n\n---\n\n### Prompt\n\nSpecify a custom system prompt file for this agent with the `prompt` config. The prompt file should contain instructions specific to the agent's purpose.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"review\": {\n      \"prompt\": \"{file:./prompts/code-review.txt}\"\n    }\n  }\n}\n```\n\nThis path is relative to where the config file is located. So this works for both the global OpenCode config and the project specific config.\n\n---\n\n### Model\n\nUse the `model` config to override the default model for this agent. Useful for using different models optimized for different tasks. For example, a faster model for planning, a more capable model for implementation.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"plan\": {\n      \"model\": \"anthropic/claude-haiku-4-20250514\"\n    }\n  }\n}\n```\n\n---\n\n### Tools\n\nControl which tools are available in this agent with the `tools` config. You can enable or disable specific tools by setting them to `true` or `false`.\n\n```json title=\"opencode.json\" {3-6,9-12}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"write\": true,\n    \"bash\": true\n  },\n  \"agent\": {\n    \"plan\": {\n      \"tools\": {\n        \"write\": false,\n        \"bash\": false\n      }\n    }\n  }\n}\n```\n\n:::note\nThe agent-specific config overrides the global config.\n:::\n\nYou can also use wildcards to control multiple tools at once. For example, to disable all tools from an MCP server:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"readonly\": {\n      \"tools\": {\n        \"mymcp_*\": false,\n        \"write\": false,\n        \"edit\": false\n      }\n    }\n  }\n}\n```\n\n[Learn more about tools](/docs/tools).\n\n---\n\n### Permissions\n\nYou can configure permissions to manage what actions an agent can take. Currently, the permissions for the `edit`, `bash`, and `webfetch` tools can be configured to:\n\n- `\"ask\"` — Prompt for approval before running the tool\n- `\"allow\"` — Allow all operations without approval\n- `\"deny\"` — Disable the tool\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"edit\": \"deny\"\n  }\n}\n```\n\nYou can override these permissions per agent.\n\n```json title=\"opencode.json\" {3-5,8-10}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"edit\": \"deny\"\n  },\n  \"agent\": {\n    \"build\": {\n      \"permission\": {\n        \"edit\": \"ask\"\n      }\n    }\n  }\n}\n```\n\nYou can also set permissions in Markdown agents.\n\n```markdown title=\"~/.config/opencode/agent/review.md\"\n---\ndescription: Code review without edits\nmode: subagent\npermission:\n  edit: deny\n  bash: ask\n  webfetch: deny\n---\n\nOnly analyze code and suggest changes.\n```\n\nYou can set permissions for specific bash commands.\n\n```json title=\"opencode.json\" {7}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"build\": {\n      \"permission\": {\n        \"bash\": {\n          \"git push\": \"ask\"\n        }\n      }\n    }\n  }\n}\n```\n\nThis can take a glob pattern.\n\n```json title=\"opencode.json\" {7}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"build\": {\n      \"permission\": {\n        \"bash\": {\n          \"git *\": \"ask\"\n        }\n      }\n    }\n  }\n}\n```\n\nAnd you can also use the `*` wildcard to manage permissions for all commands.\nWhere the specific rule can override the `*` wildcard.\n\n```json title=\"opencode.json\" {8}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"build\": {\n      \"permission\": {\n        \"bash\": {\n          \"git status\": \"allow\",\n          \"*\": \"ask\"\n        }\n      }\n    }\n  }\n}\n```\n\n[Learn more about permissions](/docs/permissions).\n\n---\n\n### Mode\n\nControl the agent's mode with the `mode` config. The `mode` option is used to determine how the agent can be used.\n\n```json title=\"opencode.json\"\n{\n  \"agent\": {\n    \"review\": {\n      \"mode\": \"subagent\"\n    }\n  }\n}\n```\n\nThe `mode` option can be set to `primary`, `subagent`, or `all`. If no `mode` is specified, it defaults to `all`.\n\n---\n\n### Additional\n\nAny other options you specify in your agent configuration will be **passed through directly** to the provider as model options. This allows you to use provider-specific features and parameters.\n\nFor example, with OpenAI's reasoning models, you can control the reasoning effort:\n\n```json title=\"opencode.json\" {6,7}\n{\n  \"agent\": {\n    \"deep-thinker\": {\n      \"description\": \"Agent that uses high reasoning effort for complex problems\",\n      \"model\": \"openai/gpt-5\",\n      \"reasoningEffort\": \"high\",\n      \"textVerbosity\": \"low\"\n    }\n  }\n}\n```\n\nThese additional options are model and provider-specific. Check your provider's documentation for available parameters.\n\n:::tip\nRun `opencode models` to see a list of the available models.\n:::\n\n---\n\n## Create agents\n\nYou can create new agents using the following command:\n\n```bash\nopencode agent create\n```\n\nThis interactive command will:\n\n1. Ask where to save the agent; global or project-specific.\n2. Description of what the agent should do.\n3. Generate an appropriate system prompt and identifier.\n4. Let you select which tools the agent can access.\n5. Finally, create a markdown file with the agent configuration.\n\n---\n\n## Use cases\n\nHere are some common use cases for different agents.\n\n- **Build agent**: Full development work with all tools enabled\n- **Plan agent**: Analysis and planning without making changes\n- **Review agent**: Code review with read-only access plus documentation tools\n- **Debug agent**: Focused on investigation with bash and read tools enabled\n- **Docs agent**: Documentation writing with file operations but no system commands\n\n---\n\n## Examples\n\nHere are some examples agents you might find useful.\n\n:::tip\nDo you have an agent you'd like to share? [Submit a PR](https://github.com/sst/opencode).\n:::\n\n---\n\n### Documentation agent\n\n```markdown title=\"~/.config/opencode/agent/docs-writer.md\"\n---\ndescription: Writes and maintains project documentation\nmode: subagent\ntools:\n  bash: false\n---\n\nYou are a technical writer. Create clear, comprehensive documentation.\n\nFocus on:\n\n- Clear explanations\n- Proper structure\n- Code examples\n- User-friendly language\n```\n\n---\n\n### Security auditor\n\n```markdown title=\"~/.config/opencode/agent/security-auditor.md\"\n---\ndescription: Performs security audits and identifies vulnerabilities\nmode: subagent\ntools:\n  write: false\n  edit: false\n---\n\nYou are a security expert. Focus on identifying potential security issues.\n\nLook for:\n\n- Input validation vulnerabilities\n- Authentication and authorization flaws\n- Data exposure risks\n- Dependency vulnerabilities\n- Configuration security issues\n```","src/content/docs/agents.mdx","03bc10df25cd60c6","cli",{id:25,data:27,body:33,filePath:34,digest:35,deferredRender:16},{title:28,description:29,editUrl:16,head:30,template:18,sidebar:31,pagefind:16,draft:20},"CLI","OpenCode CLI options and commands.",[],{hidden:20,attrs:32},{},"import { Tabs, TabItem } from \"@astrojs/starlight/components\"\n\nThe OpenCode CLI by default starts the [TUI](/docs/tui) when run without any arguments.\n\n```bash\nopencode\n```\n\nBut it also accepts commands as documented on this page. This allows you to interact with OpenCode programmatically.\n\n```bash\nopencode run \"Explain how closures work in JavaScript\"\n```\n\n---\n\n## Commands\n\nThe OpenCode CLI also has the following commands.\n\n---\n\n### agent\n\nManage agents for OpenCode.\n\n```bash\nopencode agent [command]\n```\n\n---\n\n#### create\n\nCreate a new agent with custom configuration.\n\n```bash\nopencode agent create\n```\n\nThis command will guide you through creating a new agent with a custom system prompt and tool configuration.\n\n---\n\n### auth\n\nCommand to manage credentials and login for providers.\n\n```bash\nopencode auth [command]\n```\n\n---\n\n#### login\n\nOpenCode is powered by the provider list at [Models.dev](https://models.dev), so you can use `opencode auth login` to configure API keys for any provider you'd like to use. This is stored in `~/.local/share/opencode/auth.json`.\n\n```bash\nopencode auth login\n```\n\nWhen OpenCode starts up it loads the providers from the credentials file. And if there are any keys defined in your environments or a `.env` file in your project.\n\n---\n\n#### list\n\nLists all the authenticated providers as stored in the credentials file.\n\n```bash\nopencode auth list\n```\n\nOr the short version.\n\n```bash\nopencode auth ls\n```\n\n---\n\n#### logout\n\nLogs you out of a provider by clearing it from the credentials file.\n\n```bash\nopencode auth logout\n```\n\n---\n\n### github\n\nManage the GitHub agent for repository automation.\n\n```bash\nopencode github [command]\n```\n\n---\n\n#### install\n\nInstall the GitHub agent in your repository.\n\n```bash\nopencode github install\n```\n\nThis sets up the necessary GitHub Actions workflow and guides you through the configuration process. [Learn more](/docs/github).\n\n---\n\n#### run\n\nRun the GitHub agent. This is typically used in GitHub Actions.\n\n```bash\nopencode github run\n```\n\n##### Flags\n\n| Flag      | Description                            |\n| --------- | -------------------------------------- |\n| `--event` | GitHub mock event to run the agent for |\n| `--token` | GitHub personal access token           |\n\n---\n\n### models\n\nList all available models from configured providers.\n\n```bash\nopencode models\n```\n\nThis command displays all models available across your configured providers in the format `provider/model`.\n\nThis is useful for figuring out the exact model name to use in [your config](/docs/config/).\n\n---\n\n### run\n\nRun opencode in non-interactive mode by passing a prompt directly.\n\n```bash\nopencode run [message..]\n```\n\nThis is useful for scripting, automation, or when you want a quick answer without launching the full TUI. For example.\n\n```bash \"opencode run\"\nopencode run Explain the use of context in Go\n```\n\n#### Flags\n\n| Flag         | Short | Description                                |\n| ------------ | ----- | ------------------------------------------ |\n| `--continue` | `-c`  | Continue the last session                  |\n| `--session`  | `-s`  | Session ID to continue                     |\n| `--share`    |       | Share the session                          |\n| `--model`    | `-m`  | Model to use in the form of provider/model |\n| `--agent`    |       | Agent to use                               |\n\n---\n\n### serve\n\nStart a headless opencode server for API access. Check out the [server docs](/docs/server) for the full HTTP interface.\n\n```bash\nopencode serve\n```\n\nThis starts an HTTP server that provides API access to opencode functionality without the TUI interface.\n\n#### Flags\n\n| Flag         | Short | Description           |\n| ------------ | ----- | --------------------- |\n| `--port`     | `-p`  | Port to listen on     |\n| `--hostname` | `-h`  | Hostname to listen on |\n\n---\n\n### upgrade\n\nUpdates opencode to the latest version or a specific version.\n\n```bash\nopencode upgrade [target]\n```\n\nTo upgrade to the latest version.\n\n```bash\nopencode upgrade\n```\n\nTo upgrade to a specific version.\n\n```bash\nopencode upgrade v0.1.48\n```\n\n#### Flags\n\n| Flag       | Short | Description                                                       |\n| ---------- | ----- | ----------------------------------------------------------------- |\n| `--method` | `-m`  | The installation method that was used; curl, npm, pnpm, bun, brew |\n\n---\n\n## Flags\n\nThe opencode CLI takes the following global flags.\n\n| Flag           | Short | Description                                |\n| -------------- | ----- | ------------------------------------------ |\n| `--help`       | `-h`  | Display help                               |\n| `--version`    |       | Print version number                       |\n| `--print-logs` |       | Print logs to stderr                       |\n| `--log-level`  |       | Log level (DEBUG, INFO, WARN, ERROR)       |\n| `--prompt`     | `-p`  | Prompt to use                              |\n| `--model`      | `-m`  | Model to use in the form of provider/model |\n| `--agent`      |       | Agent to use                               |\n| `--port`       |       | Port to listen on                          |\n| `--hostname`   |       | Hostname to listen on                      |","src/content/docs/cli.mdx","4269d68301a0321e","commands",{id:36,data:38,body:44,filePath:45,digest:46,deferredRender:16},{title:39,description:40,editUrl:16,head:41,template:18,sidebar:42,pagefind:16,draft:20},"Commands","Create custom commands for repetitive tasks.",[],{hidden:20,attrs:43},{},"Custom commands let you specify a prompt you want to run when that command is executed in the TUI.\n\n```bash frame=\"none\"\n/my-command\n```\n\nCustom commands are in addition to the built-in commands like `/init`, `/undo`, `/redo`, `/share`, `/help`. [Learn more](/docs/tui#commands).\n\n---\n\n## Create command files\n\nCreate markdown files in the `command/` directory to define custom commands.\n\nCreate `.opencode/command/test.md`:\n\n```md title=\".opencode/command/test.md\"\n---\ndescription: Run tests with coverage\nagent: build\nmodel: anthropic/claude-3-5-sonnet-20241022\n---\n\nRun the full test suite with coverage report and show any failures.\nFocus on the failing tests and suggest fixes.\n```\n\nThe frontmatter defines command properties. The content becomes the template.\n\nUse the command by typing `/` followed by the command name.\n\n```bash frame=\"none\"\n\"/test\"\n```\n\n---\n\n## Configure\n\nYou can add custom commands through the OpenCode config or by creating markdown files in the `command/` directory.\n\n---\n\n### JSON\n\nUse the `command` option in your OpenCode [config](/docs/config):\n\n```json title=\"opencode.jsonc\" {4-12}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"command\": {\n    // This becomes the name of the command\n    \"test\": {\n      // This is the prompt that will be sent to the LLM\n      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\",\n      // This is show as the description in the TUI\n      \"description\": \"Run tests with coverage\",\n      \"agent\": \"build\",\n      \"model\": \"anthropic/claude-3-5-sonnet-20241022\"\n    }\n  }\n}\n```\n\nNow you can run this command in the TUI:\n\n```bash frame=\"none\"\n/test\n```\n\n---\n\n### Markdown\n\nYou can also define commands using markdown files. Place them in:\n\n- Global: `~/.config/opencode/command/`\n- Per-project: `.opencode/command/`\n\n```markdown title=\"~/.config/opencode/command/test.md\"\n---\ndescription: Run tests with coverage\nagent: build\nmodel: anthropic/claude-3-5-sonnet-20241022\n---\n\nRun the full test suite with coverage report and show any failures.\nFocus on the failing tests and suggest fixes.\n```\n\nThe markdown file name becomes the command name. For example, `test.md` lets\nyou run:\n\n```bash frame=\"none\"\n/test\n```\n\n---\n\n## Prompt config\n\nThe prompts for the custom commands support several special placeholders and syntax.\n\n---\n\n### Arguments\n\nPass arguments to commands using the `$ARGUMENTS` placeholder.\n\n```md title=\".opencode/command/component.md\"\n---\ndescription: Create a new component\n---\n\nCreate a new React component named $ARGUMENTS with TypeScript support.\nInclude proper typing and basic structure.\n```\n\nRun the command with arguments:\n\n```bash frame=\"none\"\n/component Button\n```\n\nAnd `$ARGUMENTS` will be replaced with `Button`.\n\n---\n\n### Shell output\n\nUse _!`command`_ to inject [bash command](/docs/tui#bash-commands) output into your prompt.\n\nFor example, to create a custom command that analyzes test coverage:\n\n```md title=\".opencode/command/analyze-coverage.md\"\n---\ndescription: Analyze test coverage\n---\n\nHere are the current test results:\n!`npm test`\n\nBased on these results, suggest improvements to increase coverage.\n```\n\nOr to review recent changes:\n\n```md title=\".opencode/command/review-changes.md\"\n---\ndescription: Review recent changes\n---\n\nRecent git commits:\n!`git log --oneline -10`\n\nReview these changes and suggest any improvements.\n```\n\nCommands run in your project's root directory and their output becomes part of the prompt.\n\n---\n\n### File references\n\nInclude files in your command using `@` followed by the filename.\n\n```md title=\".opencode/command/review-component.md\"\n---\ndescription: Review component\n---\n\nReview the component in @src/components/Button.tsx.\nCheck for performance issues and suggest improvements.\n```\n\nThe file content gets included in the prompt automatically.\n\n---\n\n## Options\n\nLet's look at the configuration options in detail.\n\n---\n\n### Template\n\nThe `template` option defines the prompt that will be sent to the LLM when the command is executed.\n\n```json title=\"opencode.json\"\n{\n  \"command\": {\n    \"test\": {\n      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\"\n    }\n  }\n}\n```\n\nThis is a **required** config option.\n\n---\n\n### Description\n\nUse the `description` option to provide a brief description of what the command does.\n\n```json title=\"opencode.json\"\n{\n  \"command\": {\n    \"test\": {\n      \"description\": \"Run tests with coverage\"\n    }\n  }\n}\n```\n\nThis is shown as the description in the TUI when you type in the command.\n\n---\n\n### Agent\n\nUse the `agent` config to optionally specify which [agent](/docs/agents) should execute this command.\nIf this is a [subagent](/docs/agents/#subagents) the command will trigger a subagent invocation by default.\nTo disable this behavior, set `subtask` to `false`.\n\n```json title=\"opencode.json\"\n{\n  \"command\": {\n    \"review\": {\n      \"agent\": \"plan\"\n    }\n  }\n}\n```\n\nThis is an **optional** config option. If not specified, defaults to your current agent.\n\n---\n\n### Subtask\n\nUse the `subtask` boolean to force the command to trigger a [subagent](/docs/agents/#subagents) invocation.\nThis useful if you want the command to not pollute your primary context.\n\n```json title=\"opencode.json\"\n{\n  \"command\": {\n    \"analyze\": {\n      \"subtask\": true\n    }\n  }\n}\n```\n\nThis is an **optional** config option.\n\n---\n\n### Model\n\nUse the `model` config to override the default model for this command.\n\n```json title=\"opencode.json\"\n{\n  \"command\": {\n    \"analyze\": {\n      \"model\": \"anthropic/claude-3-5-sonnet-20241022\"\n    }\n  }\n}\n```\n\nThis is an **optional** config option.\n\n---\n\n## Built-in\n\nopencode includes several built-in commands like `/init`, `/undo`, `/redo`, `/share`, `/help`; [learn more](/docs/tui#commands).\n\n:::note\nCustom commands can override built-in commands.\n:::\n\nIf you define a custom command with the same name, it will override the built-in command.","src/content/docs/commands.mdx","3e2a3d274bab2c16","config",{id:47,data:49,body:55,filePath:56,digest:57,deferredRender:16},{title:50,description:51,editUrl:16,head:52,template:18,sidebar:53,pagefind:16,draft:20},"Config","Using the OpenCode JSON config.",[],{hidden:20,attrs:54},{},"You can configure OpenCode using a JSON config file.\n\n---\n\n## Format\n\nOpenCode supports both **JSON** and **JSONC** (JSON with Comments) formats.\n\n```jsonc title=\"opencode.jsonc\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  // Theme configuration\n  \"theme\": \"opencode\",\n  \"model\": \"anthropic/claude-sonnet-4-20250514\",\n  \"autoupdate\": true,\n}\n```\n\n---\n\n## Locations\n\nYou can place your config in a couple of different locations and they have a\ndifferent order of precedence.\n\n---\n\n### Global\n\nPlace your global OpenCode config in `~/.config/opencode/opencode.json`. You'll want to use the global config for things like themes, providers, or keybinds.\n\n---\n\n### Per project\n\nYou can also add a `opencode.json` in your project. It takes precedence over the global config. This is useful for configuring providers or modes specific to your project.\n\n:::tip\nPlace project specific config in the root of your project.\n:::\n\nWhen OpenCode starts up, it looks for a config file in the current directory or traverse up to the nearest Git directory.\n\nThis is also safe to be checked into Git and uses the same schema as the global one.\n\n---\n\n### Custom path\n\nYou can also specify a custom config file path using the `OPENCODE_CONFIG` environment variable. This takes precedence over the global and project configs.\n\n```bash\nexport OPENCODE_CONFIG=/path/to/my/custom-config.json\nopencode run \"Hello world\"\n```\n\n---\n\n## Schema\n\nThe config file has a schema that's defined in [**`opencode.ai/config.json`**](https://opencode.ai/config.json).\n\nYour editor should be able to validate and autocomplete based on the schema.\n\n---\n\n### TUI\n\nYou can configure TUI-specific settings through the `tui` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tui\": {\n    \"scroll_speed\": 3\n  }\n}\n```\n\n[Learn more about using the TUI here](/docs/tui).\n\n---\n\n### Tools\n\nYou can manage the tools an LLM can use through the `tools` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"write\": false,\n    \"bash\": false\n  }\n}\n```\n\n[Learn more about tools here](/docs/tools).\n\n---\n\n### Models\n\nYou can configure the providers and models you want to use in your OpenCode config through the `provider`, `model` and `small_model` options.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {},\n  \"model\": \"anthropic/claude-sonnet-4-20250514\",\n  \"small_model\": \"anthropic/claude-3-5-haiku-20241022\"\n}\n```\n\nThe `small_model` option configures a separate model for lightweight tasks like title generation. By default, OpenCode tries to use a cheaper model if one is available from your provider, otherwise it falls back to your main model.\n\nYou can also configure [local models](/docs/models#local). [Learn more](/docs/models).\n\n---\n\n### Themes\n\nYou can configure the theme you want to use in your OpenCode config through the `theme` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"theme\": \"\"\n}\n```\n\n[Learn more here](/docs/themes).\n\n---\n\n### Agents\n\nYou can configure specialized agents for specific tasks through the `agent` option.\n\n```jsonc title=\"opencode.jsonc\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"agent\": {\n    \"code-reviewer\": {\n      \"description\": \"Reviews code for best practices and potential issues\",\n      \"model\": \"anthropic/claude-sonnet-4-20250514\",\n      \"prompt\": \"You are a code reviewer. Focus on security, performance, and maintainability.\",\n      \"tools\": {\n        // Disable file modification tools for review-only agent\n        \"write\": false,\n        \"edit\": false,\n      },\n    },\n  },\n}\n```\n\nYou can also define agents using markdown files in `~/.config/opencode/agent/` or `.opencode/agent/`. [Learn more here](/docs/agents).\n\n---\n\n### Sharing\n\nYou can configure the [share](/docs/share) feature through the `share` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"share\": \"manual\"\n}\n```\n\nThis takes:\n\n- `\"manual\"` - Allow manual sharing via commands (default)\n- `\"auto\"` - Automatically share new conversations\n- `\"disabled\"` - Disable sharing entirely\n\nBy default, sharing is set to manual mode where you need to explicitly share conversations using the `/share` command.\n\n---\n\n### Commands\n\nYou can configure custom commands for repetitive tasks through the `command` option.\n\n```jsonc title=\"opencode.jsonc\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"command\": {\n    \"test\": {\n      \"template\": \"Run the full test suite with coverage report and show any failures.\\nFocus on the failing tests and suggest fixes.\",\n      \"description\": \"Run tests with coverage\",\n      \"agent\": \"build\",\n      \"model\": \"anthropic/claude-3-5-sonnet-20241022\",\n    },\n    \"component\": {\n      \"template\": \"Create a new React component named $ARGUMENTS with TypeScript support.\\nInclude proper typing and basic structure.\",\n      \"description\": \"Create a new component\",\n    },\n  },\n}\n```\n\nYou can also define commands using markdown files in `~/.config/opencode/command/` or `.opencode/command/`. [Learn more here](/docs/commands).\n\n---\n\n### Keybinds\n\nYou can customize your keybinds through the `keybinds` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"keybinds\": {}\n}\n```\n\n[Learn more here](/docs/keybinds).\n\n---\n\n### Autoupdate\n\nOpenCode will automatically download any new updates when it starts up. You can disable this with the `autoupdate` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"autoupdate\": false\n}\n```\n\n---\n\n### Formatters\n\nYou can configure code formatters through the `formatter` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"formatter\": {\n    \"prettier\": {\n      \"disabled\": true\n    },\n    \"custom-prettier\": {\n      \"command\": [\"npx\", \"prettier\", \"--write\", \"$FILE\"],\n      \"environment\": {\n        \"NODE_ENV\": \"development\"\n      },\n      \"extensions\": [\".js\", \".ts\", \".jsx\", \".tsx\"]\n    }\n  }\n}\n```\n\n[Learn more about formatters here](/docs/formatters).\n\n---\n\n### Permissions\n\nBy default, opencode **allows all operations** without requiring explicit approval. You can change this using the `permission` option.\n\nFor example, to ensure that the `edit` and `bash` tools require user approval:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"edit\": \"ask\",\n    \"bash\": \"ask\"\n  }\n}\n```\n\n[Learn more about permissions here](/docs/permissions).\n\n---\n\n### MCP servers\n\nYou can configure MCP servers you want to use through the `mcp` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {}\n}\n```\n\n[Learn more here](/docs/mcp-servers).\n\n---\n\n### Instructions\n\nYou can configure the instructions for the model you're using through the `instructions` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"instructions\": [\"CONTRIBUTING.md\", \"docs/guidelines.md\", \".cursor/rules/*.md\"]\n}\n```\n\nThis takes an array of paths and glob patterns to instruction files. [Learn more\nabout rules here](/docs/rules).\n\n---\n\n### Disabled providers\n\nYou can disable providers that are loaded automatically through the `disabled_providers` option. This is useful when you want to prevent certain providers from being loaded even if their credentials are available.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"disabled_providers\": [\"openai\", \"gemini\"]\n}\n```\n\nThe `disabled_providers` option accepts an array of provider IDs. When a provider is disabled:\n\n- It won't be loaded even if environment variables are set.\n- It won't be loaded even if API keys are configured through `opencode auth login`.\n- The provider's models won't appear in the model selection list.\n\n---\n\n## Variables\n\nYou can use variable substitution in your config files to reference environment variables and file contents.\n\n---\n\n### Env vars\n\nUse `{env:VARIABLE_NAME}` to substitute environment variables:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"model\": \"{env:OPENCODE_MODEL}\",\n  \"provider\": {\n    \"anthropic\": {\n      \"models\": {},\n      \"options\": {\n        \"apiKey\": \"{env:ANTHROPIC_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\nIf the environment variable is not set, it will be replaced with an empty string.\n\n---\n\n### Files\n\nUse `{file:path/to/file}` to substitute the contents of a file:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"instructions\": [\"./custom-instructions.md\"],\n  \"provider\": {\n    \"openai\": {\n      \"options\": {\n        \"apiKey\": \"{file:~/.secrets/openai-key}\"\n      }\n    }\n  }\n}\n```\n\nFile paths can be:\n\n- Relative to the config file directory\n- Or absolute paths starting with `/` or `~`\n\nThese are useful for:\n\n- Keeping sensitive data like API keys in separate files.\n- Including large instruction files without cluttering your config.\n- Sharing common configuration snippets across multiple config files.","src/content/docs/config.mdx","a95c8243a7b1e448","custom-tools",{id:58,data:60,body:66,filePath:67,digest:68,deferredRender:16},{title:61,description:62,editUrl:16,head:63,template:18,sidebar:64,pagefind:16,draft:20},"Custom Tools","Create tools the LLM can call in opencode.",[],{hidden:20,attrs:65},{},"Custom tools are functions you create that the LLM can call during conversations. They work alongside opencode's [built-in tools](/docs/tools) like `read`, `write`, and `bash`.\n\n---\n\n## Creating a tool\n\nTools are defined as **TypeScript** or **JavaScript** files.\n\n---\n\n### Location\n\nThey can be defined:\n\n- Locally by placing them in the `.opencode/tool/` directory of your project.\n- Or globally, by placing them in `~/.config/opencode/tool/`.\n\n---\n\n### Structure\n\nThe easiest way to create tools is using the `tool()` helper which provides type-safety and validation.\n\n```ts title=\".opencode/tool/database.ts\" {1}\nimport { tool } from \"@opencode-ai/plugin\"\n\nexport default tool({\n  description: \"Query the project database\",\n  args: {\n    query: tool.schema.string().describe(\"SQL query to execute\"),\n  },\n  async execute(args) {\n    // Your database logic here\n    return `Executed query: ${args.query}`\n  },\n})\n```\n\nThe **filename** becomes the **tool name**. The above creates a `database` tool.\n\n---\n\n### Arguments\n\nYou can use `tool.schema`, which is just [Zod](https://zod.dev), to define argument types.\n\n```ts \"tool.schema\"\nargs: {\n  query: tool.schema.string().describe(\"SQL query to execute\")\n}\n```\n\nYou can also import [Zod](https://zod.dev) directly and return a plain object:\n\n```ts {6}\nimport { z } from \"zod\"\n\nexport default {\n  description: \"Tool description\",\n  args: {\n    param: z.string().describe(\"Parameter description\"),\n  },\n  async execute(args, context) {\n    // Tool implementation\n    return \"result\"\n  },\n}\n```\n\n---\n\n## Context\n\nTools receive context about the current session:\n\n```ts title=\".opencode/tool/project.ts\" {8}\nimport { tool } from \"@opencode-ai/plugin\"\n\nexport default tool({\n  description: \"Get project information\",\n  args: {},\n  async execute(args, context) {\n    // Access context information\n    const { agent, sessionID, messageID } = context\n    return `Agent: ${agent}, Session: ${sessionID}, Message: ${messageID}`\n  },\n})\n```\n\n---\n\n## Multiple tools per file\n\nYou can also export multiple tools from a single file. Each export becomes **a separate tool** with the name **`<filename>_<exportname>`**:\n\n```ts title=\".opencode/tool/math.ts\"\nimport { tool } from \"@opencode-ai/plugin\"\n\nexport const add = tool({\n  description: \"Add two numbers\",\n  args: {\n    a: tool.schema.number().describe(\"First number\"),\n    b: tool.schema.number().describe(\"Second number\"),\n  },\n  async execute(args) {\n    return args.a + args.b\n  },\n})\n\nexport const multiply = tool({\n  description: \"Multiply two numbers\",\n  args: {\n    a: tool.schema.number().describe(\"First number\"),\n    b: tool.schema.number().describe(\"Second number\"),\n  },\n  async execute(args) {\n    return args.a * args.b\n  },\n})\n```\n\nThis creates two tools: `math_add` and `math_multiply`.","src/content/docs/custom-tools.mdx","e23a4aeac4636e37","enterprise",{id:69,data:71,body:77,filePath:78,digest:79,deferredRender:16},{title:72,description:73,editUrl:16,head:74,template:18,sidebar:75,pagefind:16,draft:20},"Enterprise","Using OpenCode in your organization.",[],{hidden:20,attrs:76},{},"import config from \"../../../config.mjs\"\nexport const email = `mailto:${config.email}`\n\nOpenCode does not store any of your code or context data. This makes it easy for\nyou to use OpenCode at your organization.\n\nTo get started, we recommend:\n\n1. Do a trial internally with your team.\n2. **<a href={email}>Contact us</a>** to discuss pricing and implementation options.\n\n---\n\n## Trial\n\nSince OpenCode is open source and does not store any of your code or context data, your developers can simply [get started](/docs/) and carry out a trial.\n\n---\n\n### Data handling\n\n**opencode does not store your code or context data.** All processing happens locally or through direct API calls to your AI provider.\n\nThe only caveat here is the optional `/share` feature.\n\n---\n\n#### Sharing conversations\n\nIf a user enables the `/share` feature, the conversation and the data associated with it are sent to the service we use to host these shares pages at opencode.ai.\n\nThe data is currently served through our CDN's edge network, and is cached on the edge near your users.\n\nWe recommend you disable this for your trial.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"share\": \"disabled\"\n}\n```\n\n[Learn more about sharing](/docs/share).\n\n---\n\n### Code ownership\n\n**You own all code produced by opencode.** There are no licensing restrictions or ownership claims.\n\n---\n\n## Deployment\n\nOnce you have completed your trial and you are ready to self-host opencode at\nyour organization, you can **<a href={email}>contact us</a>** to discuss\npricing and implementation options.\n\n---\n\n### SSO\n\nSSO integration can be implemented for enterprise deployments after your trial.\nThis will allow your team's session data and shared conversations to be protected\nby your enterprise's authentication system.\n\n---\n\n### Private NPM\n\nopencode supports private npm registries through Bun's native `.npmrc` file support. If your organization uses a private registry, such as JFrog Artifactory, Nexus, or similar, ensure developers are authenticated before running opencode.\n\nTo set up authentication with your private registry:\n\n```bash\nnpm login --registry=https://your-company.jfrog.io/api/npm/npm-virtual/\n```\n\nThis creates `~/.npmrc` with authentication details. opencode will automatically\npick this up.\n\n:::caution\nYou must be logged into the private registry before running opencode.\n:::\n\nAlternatively, you can manually configure a `.npmrc` file:\n\n```bash title=\"~/.npmrc\"\nregistry=https://your-company.jfrog.io/api/npm/npm-virtual/\n//your-company.jfrog.io/api/npm/npm-virtual/:_authToken=${NPM_AUTH_TOKEN}\n```\n\nDevelopers must be logged into the private registry before running opencode to ensure packages can be installed from your enterprise registry.\n\n---\n\n### Self-hosting\n\nThe share feature can be self-hosted and the share pages can be made accessible\nonly after the user has been authenticated.","src/content/docs/enterprise.mdx","b30e3a0516914522","formatters",{id:80,data:82,body:88,filePath:89,digest:90,deferredRender:16},{title:83,description:84,editUrl:16,head:85,template:18,sidebar:86,pagefind:16,draft:20},"Formatters","OpenCode uses language specific formatters.",[],{hidden:20,attrs:87},{},"OpenCode automatically formats files after they are written or edited using language-specific formatters. This ensures that the code that is generated follows the code styles of your project.\n\n---\n\n## Built-in\n\nOpenCode comes with several built-in formatters for popular languages and frameworks. Below is a list of the formatters, supported file extensions, and commands or config options it needs.\n\n| Formatter      | Extensions                                                                                               | Requirements                            |\n| -------------- | -------------------------------------------------------------------------------------------------------- | --------------------------------------- |\n| gofmt          | .go                                                                                                      | `gofmt` command available               |\n| mix            | .ex, .exs, .eex, .heex, .leex, .neex, .sface                                                             | `mix` command available                 |\n| prettier       | .js, .jsx, .ts, .tsx, .html, .css, .md, .json, .yaml, and [more](https://prettier.io/docs/en/index.html) | `prettier` dependency in `package.json` |\n| biome          | .js, .jsx, .ts, .tsx, .html, .css, .md, .json, .yaml, and [more](https://biomejs.dev/)                   | `biome.json(c)` config file             |\n| zig            | .zig, .zon                                                                                               | `zig` command available                 |\n| clang-format   | .c, .cpp, .h, .hpp, .ino, and [more](https://clang.llvm.org/docs/ClangFormat.html)                       | `.clang-format` config file             |\n| ktlint         | .kt, .kts                                                                                                | `ktlint` command available              |\n| ruff           | .py, .pyi                                                                                                | `ruff` command available with config    |\n| rubocop        | .rb, .rake, .gemspec, .ru                                                                                | `rubocop` command available             |\n| standardrb     | .rb, .rake, .gemspec, .ru                                                                                | `standardrb` command available          |\n| htmlbeautifier | .erb, .html.erb                                                                                          | `htmlbeautifier` command available      |\n\nSo if your project has `prettier` in your `package.json`, OpenCode will automatically use it.\n\n---\n\n## How it works\n\nWhen OpenCode writes or edits a file, it:\n\n1. Checks the file extension against all enabled formatters.\n2. Runs the appropriate formatter command on the file.\n3. Applies the formatting changes automatically.\n\nThis process happens in the background, ensuring your code styles are maintained without any manual steps.\n\n---\n\n## Configure\n\nYou can customize formatters through the `formatter` section in your OpenCode config.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"formatter\": {}\n}\n```\n\nEach formatter configuration supports the following:\n\n| Property      | Type     | Description                                             |\n| ------------- | -------- | ------------------------------------------------------- |\n| `disabled`    | boolean  | Set this to `true` to disable the formatter             |\n| `command`     | string[] | The command to run for formatting                       |\n| `environment` | object   | Environment variables to set when running the formatter |\n| `extensions`  | string[] | File extensions this formatter should handle            |\n\nLet's look at some examples.\n\n---\n\n### Disabling formatters\n\nTo disable a specific formatter, set `disabled` to `true`:\n\n```json title=\"opencode.json\" {5}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"formatter\": {\n    \"prettier\": {\n      \"disabled\": true\n    }\n  }\n}\n```\n\n---\n\n### Custom formatters\n\nYou can override the built-in formatters or add new ones by specifying the command, environment variables, and file extensions:\n\n```json title=\"opencode.json\" {4-14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"formatter\": {\n    \"prettier\": {\n      \"command\": [\"npx\", \"prettier\", \"--write\", \"$FILE\"],\n      \"environment\": {\n        \"NODE_ENV\": \"development\"\n      },\n      \"extensions\": [\".js\", \".ts\", \".jsx\", \".tsx\"]\n    },\n    \"custom-markdown-formatter\": {\n      \"command\": [\"deno\", \"fmt\", \"$FILE\"],\n      \"extensions\": [\".md\"]\n    }\n  }\n}\n```\n\nThe **`$FILE` placeholder** in the command will be replaced with the path to the file being formatted.","src/content/docs/formatters.mdx","d4cf2d7ad560a421","github",{id:91,data:93,body:99,filePath:100,digest:101,deferredRender:16},{title:94,description:95,editUrl:16,head:96,template:18,sidebar:97,pagefind:16,draft:20},"GitHub","Use opencode in GitHub issues and pull-requests.",[],{hidden:20,attrs:98},{},"opencode integrates with your GitHub workflow. Mention `/opencode` or `/oc` in your comment, and opencode will execute tasks within your GitHub Actions runner.\n\n---\n\n## Features\n\n- **Triage issues**: Ask opencode to look into an issue and explain it to you.\n- **Fix and implement**: Ask opencode to fix an issue or implement a feature. And it will work in a new branch and submits a PR with all the changes.\n- **Secure**: opencode runs inside your GitHub's runners.\n\n---\n\n## Installation\n\nRun the following command in a project that is in a GitHub repo:\n\n```bash\nopencode github install\n```\n\nThis will walk you through installing the GitHub app, creating the workflow, and setting up secrets.\n\n---\n\n### Manual Setup\n\nOr you can set it up manually.\n\n1. **Install the GitHub app**\n\n   Head over to [**github.com/apps/opencode-agent**](https://github.com/apps/opencode-agent). Make sure it's installed on the target repository.\n\n2. **Add the workflow**\n\n   Add the following workflow file to `.github/workflows/opencode.yml` in your repo. Make sure to set the appropriate `model` and required API keys in `env`.\n\n   ```yml title=\".github/workflows/opencode.yml\" {24,26}\n   name: opencode\n\n   on:\n     issue_comment:\n       types: [created]\n\n   jobs:\n     opencode:\n       if: |\n         contains(github.event.comment.body, '/oc') ||\n         contains(github.event.comment.body, '/opencode')\n       runs-on: ubuntu-latest\n       permissions:\n         id-token: write\n       steps:\n         - name: Checkout repository\n           uses: actions/checkout@v4\n           with:\n             fetch-depth: 1\n\n         - name: Run opencode\n           uses: sst/opencode/github@latest\n           env:\n             ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n           with:\n             model: anthropic/claude-sonnet-4-20250514\n             # share: true\n             # github_token: xxxx\n   ```\n\n3. **Store the API keys in secrets**\n\n   In your organization or project **settings**, expand **Secrets and variables** on the left and select **Actions**. And add the required API keys.\n\n---\n\n## Configuration\n\n- `model`: The model to use with opencode. Takes the format of `provider/model`. This is **required**.\n- `share`: Whether to share the opencode session. Defaults to **true** for public repositories.\n- `token`: Optional GitHub access token for performing operations such as creating comments, commiting changes, and opening pull requests. By default, opencode uses the installation access token from the opencode GitHub App, so commits, comments, and pull requests appear as coming from the app.\n\n  Alternatively, you can use the GitHub Action runner's [built-in `GITHUB_TOKEN`](https://docs.github.com/en/actions/tutorials/authenticate-with-github_token) without installing the opencode GitHub App. Just make sure to grant the required permissions in your workflow:\n\n  ```yaml\n  permissions:\n    id-token: write\n    contents: write\n    pull-requests: write\n    issues: write\n  ```\n\n  You can also use a [personal access tokens](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)(PAT) if preferred.\n\n---\n\n## Examples\n\nHere are some examples of how you can use opencode in GitHub.\n\n- **Explain an issue**\n\n  Add this comment in a GitHub issue.\n\n  ```\n  /opencode explain this issue\n  ```\n\n  opencode will read the entire thread, including all comments, and reply with a clear explanation.\n\n- **Fix an issue**\n\n  In a GitHub issue, say:\n\n  ```\n  /opencode fix this\n  ```\n\n  And opencode will create a new branch, implement the changes, and open a PR with the changes.\n\n- **Review PRs and make changes**\n\n  Leave the following comment on a GitHub PR.\n\n  ```\n  Delete the attachment from S3 when the note is removed /oc\n  ```\n\n  opencode will implement the requested change and commit it to the same PR.","src/content/docs/github.mdx","accffac25845402f","gitlab",{id:102,data:104,body:110,filePath:111,digest:112,deferredRender:16},{title:105,description:106,editUrl:16,head:107,template:18,sidebar:108,pagefind:16,draft:20},"GitLab","Use opencode in GitLab issues and merge requests.",[],{hidden:20,attrs:109},{},"opencode integrates with your GitLab workflow.\nMention `@opencode` in a comment, and opencode will execute tasks within your GitLab CI pipeline.\n\n---\n\n## Features\n\n- **Triage issues**: Ask opencode to look into an issue and explain it to you.\n- **Fix and implement**: Ask opencode to fix an issue or implement a feature.\n  It will work create a new branch and raised a merge request with the changes.\n- **Secure**: opencode runs on your GitLab runners.\n\n---\n\n## Setup\n\nopencode runs in your GitLab CI/CD pipeline, here's what you'll need to set it up:\n\n:::tip\nCheck out the [**GitLab docs**](https://docs.gitlab.com/user/duo_agent_platform/agent_assistant/) for up to date instructions.\n:::\n\n1.  Configure your GitLab environment\n2.  Set up CI/CD\n3.  Get an AI model provider API key\n4.  Create a service account\n5.  Configure CI/CD variables\n6.  Create a flow config file, here's an example:\n\n        <details>\n\n    <summary>Flow configuration</summary>\n\n    ```yaml\n    image: node:22-slim\n    commands:\n      - echo \"Installing opencode\"\n      - npm install --global opencode-ai\n      - echo \"Installing glab\"\n      - export GITLAB_TOKEN=$GITLAB_TOKEN_OPENCODE\n      - apt-get update --quiet && apt-get install --yes curl wget gpg git && rm --recursive --force /var/lib/apt/lists/*\n      - curl --silent --show-error --location \"https://raw.githubusercontent.com/upciti/wakemeops/main/assets/install_repository\" | bash\n      - apt-get install --yes glab\n      - echo \"Configuring glab\"\n      - echo $GITLAB_HOST\n      - echo \"Creating opencode auth configuration\"\n      - mkdir --parents ~/.local/share/opencode\n      - |\n        cat > ~/.local/share/opencode/auth.json << EOF\n        {\n          \"anthropic\": {\n            \"type\": \"api\",\n            \"key\": \"$ANTHROPIC_API_KEY\"\n          }\n        }\n        EOF\n      - echo \"Configuring git\"\n      - git config --global user.email \"opencode@gitlab.com\"\n      - git config --global user.name \"Opencode\"\n      - echo \"Testing glab\"\n      - glab issue list\n      - echo \"Running Opencode\"\n      - |\n        opencode run \"\n        You are an AI assistant helping with GitLab operations.\n\n        Context: $AI_FLOW_CONTEXT\n        Task: $AI_FLOW_INPUT\n        Event: $AI_FLOW_EVENT\n\n        Please execute the requested task using the available GitLab tools.\n        Be thorough in your analysis and provide clear explanations.\n\n        <important>\n        Please use the glab CLI to access data from GitLab. The glab CLI has already been authenticated. You can run the corresponding commands.\n\n        If you are asked to summarise an MR or issue or asked to provide more information then please post back a note to the MR/Issue so that the user can see it.\n        You don't need to commit or push up changes, those will be done automatically based on the file changes you make.\n        </important>\n        \"\n      - git checkout --branch $CI_WORKLOAD_REF origin/$CI_WORKLOAD_REF\n      - echo \"Checking for git changes and pushing if any exist\"\n      - |\n        if ! git diff --quiet || ! git diff --cached --quiet || [ --not --zero \"$(git ls-files --others --exclude-standard)\" ]; then\n          echo \"Git changes detected, adding and pushing...\"\n          git add .\n          if git diff --cached --quiet; then\n            echo \"No staged changes to commit\"\n          else\n            echo \"Committing changes to branch: $CI_WORKLOAD_REF\"\n            git commit --message \"Codex changes\"\n            echo \"Pushing changes up to $CI_WORKLOAD_REF\"\n            git push https://gitlab-ci-token:$GITLAB_TOKEN@$GITLAB_HOST/gl-demo-ultimate-dev-ai-epic-17570/test-java-project.git $CI_WORKLOAD_REF\n            echo \"Changes successfully pushed\"\n          fi\n        else\n          echo \"No git changes detected, skipping push\"\n        fi\n    variables:\n      - ANTHROPIC_API_KEY\n      - GITLAB_TOKEN_OPENCODE\n      - GITLAB_HOST\n    ```\n\n        </details>\n\nYou can refer to the [GitLab CLI agents docs](https://docs.gitlab.com/user/duo_agent_platform/agent_assistant/) for detailed instructions.\n\n---\n\n## Examples\n\nHere are some examples of how you can use opencode in GitLab.\n\n:::tip\nYou can configure to use a different trigger phrase than `@opencode`.\n:::\n\n- **Explain an issue**\n\n  Add this comment in a GitLab issue.\n\n  ```\n  @opencode explain this issue\n  ```\n\n  opencode will read the issue and reply with a clear explanation.\n\n- **Fix an issue**\n\n  In a GitLab issue, say:\n\n  ```\n  @opencode fix this\n  ```\n\n  opencode will create a new branch, implement the changes, and open a merge request with the changes.\n\n- **Review merge requests**\n\n  Leave the following comment on a GitLab merge request.\n\n  ```\n  @opencode review this merge request\n  ```\n\n  opencode will review the merge request and provide feedback.","src/content/docs/gitlab.mdx","cacd68248284fb0c","ide",{id:113,data:115,body:121,filePath:122,digest:123,deferredRender:16},{title:116,description:117,editUrl:16,head:118,template:18,sidebar:119,pagefind:16,draft:20},"IDE","The OpenCode extension for VS Code, Cursor, and other IDEs",[],{hidden:20,attrs:120},{},"OpenCode integrates with VS Code, Cursor, or any IDE that supports a terminal. Just run `opencode` in the terminal to get started.\n\n---\n\n## Usage\n\n- **Quick Launch**: Use `Cmd+Esc` (Mac) or `Ctrl+Esc` (Windows/Linux) to open OpenCode in a split terminal view, or focus an existing terminal session if one is already running.\n- **New Session**: Use `Cmd+Shift+Esc` (Mac) or `Ctrl+Shift+Esc` (Windows/Linux) to start a new OpenCode terminal session, even if one is already open. You can also click the OpenCode button in the UI.\n- **Context Awareness**: Automatically share your current selection or tab with OpenCode.\n- **File Reference Shortcuts**: Use `Cmd+Option+K` (Mac) or `Alt+Ctrl+K` (Linux/Windows) to insert file references. For example, `@File#L37-42`.\n\n---\n\n## Installation\n\nTo install OpenCode on VS Code and popular forks like Cursor, Windsurf, VSCodium:\n\n1. Open VS Code\n2. Open the integrated terminal\n3. Run `opencode` - the extension installs automatically\n\nIf on the other hand you want to use your own IDE when you run `/editor` or `/export` from the TUI, you'll need to set `export EDITOR=\"code --wait\"`. [Learn more](/docs/tui/#editor-setup).\n\n---\n\n### Manual Install\n\nSearch for **OpenCode** in the Extension Marketplace and click **Install**.\n\n---\n\n### Troubleshooting\n\nIf the extension fails to install automatically:\n\n- Ensure you’re running `opencode` in the integrated terminal.\n- Confirm the CLI for your IDE is installed:\n  - For VS Code: `code` command\n  - For Cursor: `cursor` command\n  - For Windsurf: `windsurf` command\n  - For VSCodium: `codium` command\n  - If not, run `Cmd+Shift+P` (Mac) or `Ctrl+Shift+P` (Windows/Linux) and search for \"Shell Command: Install 'code' command in PATH\" (or the equivalent for your IDE)\n- Ensure VS Code has permission to install extensions","src/content/docs/ide.mdx","d5a0b22575f6f04f","index",{id:124,data:126,body:132,filePath:133,digest:134,deferredRender:16},{title:127,description:128,editUrl:16,head:129,template:18,sidebar:130,pagefind:16,draft:20},"Intro","Get started with OpenCode.",[],{hidden:20,attrs:131},{},"import { Tabs, TabItem } from \"@astrojs/starlight/components\"\nimport config from \"../../../config.mjs\"\nexport const console = config.console\n\n[**OpenCode**](/) is an AI coding agent built for the terminal.\n\n![OpenCode TUI with the opencode theme](../../assets/lander/screenshot.png)\n\nLet's get started.\n\n---\n\n#### Prerequisites\n\nTo use OpenCode, you'll need:\n\n1. A modern terminal emulator like:\n   - [WezTerm](https://wezterm.org), cross-platform\n   - [Alacritty](https://alacritty.org), cross-platform\n   - [Ghostty](https://ghostty.org), Linux and macOS\n   - [Kitty](https://sw.kovidgoyal.net/kitty/), Linux and macOS\n\n2. API keys for the LLM providers you want to use.\n\n---\n\n## Install\n\nThe easiest way to install OpenCode is through the install script.\n\n```bash\ncurl -fsSL https://opencode.ai/install | bash\n```\n\nYou can also install it with the following commands:\n\n- **Using Node.js**\n\n  <Tabs>\n    <TabItem label=\"npm\">\n      ```bash\n      npm install -g opencode-ai\n      ```\n    </TabItem>\n    <TabItem label=\"Bun\">\n      ```bash\n      bun install -g opencode-ai\n      ```\n    </TabItem>\n    <TabItem label=\"pnpm\">\n      ```bash\n      pnpm install -g opencode-ai\n      ```\n    </TabItem>\n    <TabItem label=\"Yarn\">\n      ```bash\n      yarn global add opencode-ai\n      ```\n    </TabItem>\n  </Tabs>\n\n- **Using Homebrew on macOS and Linux**\n\n  ```bash\n  brew install sst/tap/opencode\n  ```\n\n- **Using Paru on Arch Linux**\n\n  ```bash\n  paru -S opencode-bin\n  ```\n\n#### Windows\n\n- **Using Chocolatey**\n\n  ```bash\n  choco install opencode\n  ```\n\n- **Using WinGet**\n\n  ```bash\n  winget install opencode\n  ```\n\n- **Using Scoop**\n\n  ```bash\n  scoop bucket add extras\n  scoop install extras/opencode\n  ```\n\n- **Using NPM**\n\n  ```bash\n  npm install -g opencode-ai\n  ```\n\nSupport for installing OpenCode on Windows using Bun is currently in progress.\n\nYou can also grab the binary from the [Releases](https://github.com/sst/opencode/releases).\n\n---\n\n## Configure\n\nWith OpenCode you can use any LLM provider by configuring their API keys.\n\nIf you are new to using LLM providers, we recommend using [OpenCode Zen](/docs/zen).\nIt's a curated list of models that have been tested and verified by the OpenCode\nteam.\n\n1. Run `opencode auth login`, select opencode, and head to [opencode.ai/auth](https://opencode.ai/auth).\n2. Sign in, add your billing details, and copy your API key.\n3. Paste your API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  opencode\n   │\n   ●  Create an api key at https://opencode.ai/auth\n   │\n   ◆  Enter your API key\n   │  _\n   └\n   ```\n\nAlternatively, you can select one of the other providers. [Learn more](/docs/providers#directory).\n\n---\n\n## Initialize\n\nNow that you've configured a provider, you can navigate to a project that\nyou want to work on.\n\n```bash\ncd /path/to/project\n```\n\nAnd run OpenCode.\n\n```bash\nopencode\n```\n\nNext, initialize OpenCode for the project by running the following command.\n\n```bash frame=\"none\"\n/init\n```\n\nThis will get OpenCode to analyze your project and create an `AGENTS.md` file in\nthe project root.\n\n:::tip\nYou should commit your project's `AGENTS.md` file to Git.\n:::\n\nThis helps OpenCode understand the project structure and the coding patterns\nused.\n\n---\n\n## Usage\n\nYou are now ready to use OpenCode to work on your project. Feel free to ask it\nanything!\n\nIf you are new to using an AI coding agent, here are some examples that might\nhelp.\n\n---\n\n### Ask questions\n\nYou can ask OpenCode to explain the codebase to you.\n\n:::tip\nUse the `@` key to fuzzy search for files in the project.\n:::\n\n```txt frame=\"none\" \"@packages/functions/src/api/index.ts\"\nHow is authentication handled in @packages/functions/src/api/index.ts\n```\n\nThis is helpful if there's a part of the codebase that you didn't work on.\n\n---\n\n### Add features\n\nYou can ask OpenCode to add new features to your project. Though we first recommend asking it to create a plan.\n\n1. **Create a plan**\n\n   OpenCode has a _Plan mode_ that disables its ability to make changes and\n   instead suggest _how_ it'll implement the feature.\n\n   Switch to it using the **Tab** key. You'll see an indicator for this in the lower right corner.\n\n   ```bash frame=\"none\" title=\"Switch to Plan mode\"\n   <TAB>\n   ```\n\n   Now let's describe what we want it to do.\n\n   ```txt frame=\"none\"\n   When a user deletes a note, we'd like to flag it as deleted in the database.\n   Then create a screen that shows all the recently deleted notes.\n   From this screen, the user can undelete a note or permanently delete it.\n   ```\n\n   You want to give OpenCode enough details to understand what you want. It helps\n   to talk to it like you are talking to a junior developer on your team.\n\n   :::tip\n   Give OpenCode plenty of context and examples to help it understand what you\n   want.\n   :::\n\n2. **Iterate on the plan**\n\n   Once it gives you a plan, you can give it feedback or add more details.\n\n   ```txt frame=\"none\"\n   We'd like to design this new screen using a design I've used before.\n   [Image #1] Take a look at this image and use it as a reference.\n   ```\n\n   :::tip\n   Drag and drop images into the terminal to add them to the prompt.\n   :::\n\n   OpenCode can scan any images you give it and add them to the prompt. You can\n   do this by dragging and dropping an image into the terminal.\n\n3. **Build the feature**\n\n   Once you feel comfortable with the plan, switch back to _Build mode_ by\n   hitting the **Tab** key again.\n\n   ```bash frame=\"none\"\n   <TAB>\n   ```\n\n   And asking it to make the changes.\n\n   ```bash frame=\"none\"\n   Sounds good! Go ahead and make the changes.\n   ```\n\n---\n\n### Make changes\n\nFor more straightforward changes, you can ask OpenCode to directly build it\nwithout having to review the plan first.\n\n```txt frame=\"none\" \"@packages/functions/src/settings.ts\" \"@packages/functions/src/notes.ts\"\nWe need to add authentication to the /settings route. Take a look at how this is\nhandled in the /notes route in @packages/functions/src/notes.ts and implement\nthe same logic in @packages/functions/src/settings.ts\n```\n\nYou want to make sure you provide a good amount of detail so OpenCode makes the right\nchanges.\n\n---\n\n### Undo changes\n\nLet's say you ask OpenCode to make some changes.\n\n```txt frame=\"none\" \"@packages/functions/src/api/index.ts\"\nCan you refactor the function in @packages/functions/src/api/index.ts?\n```\n\nBut you realize that it is not what you wanted. You **can undo** the changes\nusing the `/undo` command.\n\n```bash frame=\"none\"\n/undo\n```\n\nOpenCode will now revert the changes you made and show your original message\nagain.\n\n```txt frame=\"none\" \"@packages/functions/src/api/index.ts\"\nCan you refactor the function in @packages/functions/src/api/index.ts?\n```\n\nFrom here you can tweak the prompt and ask OpenCode to try again.\n\n:::tip\nYou can run `/undo` multiple times to undo multiple changes.\n:::\n\nOr you **can redo** the changes using the `/redo` command.\n\n```bash frame=\"none\"\n/redo\n```\n\n---\n\n## Share\n\nThe conversations that you have with OpenCode can be [shared with your\nteam](/docs/share).\n\n```bash frame=\"none\"\n/share\n```\n\nThis will create a link to the current conversation and copy it to your clipboard.\n\n:::note\nConversations are not shared by default.\n:::\n\nHere's an [example conversation](https://opencode.ai/s/4XP1fce5) with OpenCode.\n\n---\n\n## Customize\n\nAnd that's it! You are now a pro at using OpenCode.\n\nTo make it your own, we recommend [picking a theme](/docs/themes), [customizing the keybinds](/docs/keybinds), [configuring code formatters](/docs/formatters), [creating custom commands](/docs/commands), or playing around with the [OpenCode config](/docs/config).","src/content/docs/index.mdx","23cee5b0a6a628f5","keybinds",{id:135,data:137,body:143,filePath:144,digest:145,deferredRender:16},{title:138,description:139,editUrl:16,head:140,template:18,sidebar:141,pagefind:16,draft:20},"Keybinds","Customize your keybinds.",[],{hidden:20,attrs:142},{},"OpenCode has a list of keybinds that you can customize through the OpenCode config.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"keybinds\": {\n    \"leader\": \"ctrl+x\",\n    \"app_help\": \"<leader>h\",\n    \"app_exit\": \"ctrl+c,<leader>q\",\n    \"editor_open\": \"<leader>e\",\n    \"theme_list\": \"<leader>t\",\n    \"project_init\": \"<leader>i\",\n    \"tool_details\": \"<leader>d\",\n    \"thinking_blocks\": \"<leader>b\",\n    \"session_export\": \"<leader>x\",\n    \"session_new\": \"<leader>n\",\n    \"session_list\": \"<leader>l\",\n    \"session_share\": \"<leader>s\",\n    \"session_unshare\": \"none\",\n    \"session_interrupt\": \"esc\",\n    \"session_compact\": \"<leader>c\",\n    \"session_child_cycle\": \"ctrl+right\",\n    \"session_child_cycle_reverse\": \"ctrl+left\",\n    \"messages_page_up\": \"pgup\",\n    \"messages_page_down\": \"pgdown\",\n    \"messages_half_page_up\": \"ctrl+alt+u\",\n    \"messages_half_page_down\": \"ctrl+alt+d\",\n    \"messages_first\": \"ctrl+g\",\n    \"messages_last\": \"ctrl+alt+g\",\n    \"messages_copy\": \"<leader>y\",\n    \"messages_undo\": \"<leader>u\",\n    \"messages_redo\": \"<leader>r\",\n    \"model_list\": \"<leader>m\",\n    \"model_cycle_recent\": \"f2\",\n    \"model_cycle_recent_reverse\": \"shift+f2\",\n    \"agent_list\": \"<leader>a\",\n    \"agent_cycle\": \"tab\",\n    \"agent_cycle_reverse\": \"shift+tab\",\n    \"input_clear\": \"ctrl+c\",\n    \"input_paste\": \"ctrl+v\",\n    \"input_submit\": \"enter\",\n    \"input_newline\": \"shift+enter,ctrl+j\"\n  }\n}\n```\n\n---\n\n## Leader key\n\nOpenCode uses a `leader` key for most keybinds. This avoids conflicts in your terminal.\n\nBy default, `ctrl+x` is the leader key and most actions require you to first press the leader key and then the shortcut. For example, to start a new session you first press `ctrl+x` and then press `n`.\n\nYou don't need to use a leader key for your keybinds but we recommend doing so.\n\n---\n\n## Disable keybind\n\nYou can disable a keybind by adding the key to your config with a value of \"none\".\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"keybinds\": {\n    \"session_compact\": \"none\"\n  }\n}\n```","src/content/docs/keybinds.mdx","d165a35e83be8455","lsp",{id:146,data:148,body:154,filePath:155,digest:156,deferredRender:16},{title:149,description:150,editUrl:16,head:151,template:18,sidebar:152,pagefind:16,draft:20},"LSP Servers","OpenCode integrates with your LSP servers.",[],{hidden:20,attrs:153},{},"OpenCode integrates with your Language Server Protocol (LSP) to help the LLM interact with your codebase. It uses diagnostics to provide feedback to the LLM.\n\n---\n\n## Built-in\n\nOpenCode comes with several built-in LSP servers for popular languages:\n\n| LSP Server | Extensions                                           | Requirements                        |\n| ---------- | ---------------------------------------------------- | ----------------------------------- |\n| typescript | .ts, .tsx, .js, .jsx, .mjs, .cjs, .mts, .cts         | `typescript` dependency in project  |\n| eslint     | .ts, .tsx, .js, .jsx, .mjs, .cjs, .mts, .cts, .vue   | `eslint` dependency in project      |\n| gopls      | .go                                                  | `go` command available              |\n| ruby-lsp   | .rb, .rake, .gemspec, .ru                            | `ruby` and `gem` commands available |\n| pyright    | .py, .pyi                                            | `pyright` dependency installed      |\n| elixir-ls  | .ex, .exs                                            | `elixir` command available          |\n| zls        | .zig, .zon                                           | `zig` command available             |\n| csharp     | .cs                                                  | `.NET SDK` installed                |\n| vue        | .vue                                                 | Auto-installs for Vue projects      |\n| rust       | .rs                                                  | `rust-analyzer` command available   |\n| clangd     | .c, .cpp, .cc, .cxx, .c++, .h, .hpp, .hh, .hxx, .h++ | Auto-installs for C/C++ projects    |\n| svelte     | .svelte                                              | Auto-installs for Svelte projects   |\n| jdtls      | .java                                                | `Java SDK (version 21+)` installed  |\n\nLSP servers are automatically enabled when one of the above file extensions are detected and the requirements are met.\n\n:::note\nYou can disable automatic LSP server downloads by setting the `OPENCODE_DISABLE_LSP_DOWNLOAD` environment variable to `true`.\n:::\n\n---\n\n## How It Works\n\nWhen opencode opens a file, it:\n\n1. Checks the file extension against all enabled LSP servers.\n2. Starts the appropriate LSP server if not already running.\n\n---\n\n## Configure\n\nYou can customize LSP servers through the `lsp` section in your opencode config.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"lsp\": {}\n}\n```\n\nEach LSP server supports the following:\n\n| Property         | Type     | Description                                       |\n| ---------------- | -------- | ------------------------------------------------- |\n| `disabled`       | boolean  | Set this to `true` to disable the LSP server      |\n| `command`        | string[] | The command to start the LSP server               |\n| `extensions`     | string[] | File extensions this LSP server should handle     |\n| `env`            | object   | Environment variables to set when starting server |\n| `initialization` | object   | Initialization options to send to the LSP server  |\n\nLet's look at some examples.\n\n---\n\n### Disabling LSP servers\n\nTo disable a specific LSP server, set `disabled` to `true`:\n\n```json title=\"opencode.json\" {5}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"lsp\": {\n    \"typescript\": {\n      \"disabled\": true\n    }\n  }\n}\n```\n\n---\n\n### Custom LSP servers\n\nYou can add custom LSP servers by specifying the command and file extensions:\n\n```json title=\"opencode.json\" {4-7}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"lsp\": {\n    \"custom-lsp\": {\n      \"command\": [\"custom-lsp-server\", \"--stdio\"],\n      \"extensions\": [\".custom\"]\n    }\n  }\n}\n```","src/content/docs/lsp.mdx","e3d91ed50179bdee","mcp-servers",{id:157,data:159,body:165,filePath:166,digest:167,deferredRender:16},{title:160,description:161,editUrl:16,head:162,template:18,sidebar:163,pagefind:16,draft:20},"MCP servers","Add local and remote MCP tools.",[],{hidden:20,attrs:164},{},"You can add external tools to OpenCode using the _Model Context Protocol_, or MCP.\n\nOpenCode supports both:\n\n- Local servers\n- Remote servers\n\nOnce added, MCP tools are automatically available to the LLM alongside built-in tools.\n\n:::note\nOAuth support for MCP servers is coming soon.\n:::\n\n---\n\n## Caveats\n\nWhen you use an MCP server, it adds to the context. This can quickly add up if\nyou have a lot of tools. So we recommend being careful with which MCP servers\nyou use.\n\n:::tip\nMCP servers add to your context, so you want to be careful with which\nones you enable.\n:::\n\nCertain MCP servers, like the GitHub MCP server tend to add a lot of tokens and\ncan easily exceed the context limit.\n\n---\n\n## Configure\n\nYou can define MCP servers in your OpenCode config under `mcp`. Add each MCP\nwith a unique name. You can refer to that MCP by name when prompting the LLM.\n\n```jsonc title=\"opencode.jsonc\" {6}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"name-of-mcp-server\": {\n      // ...\n      \"enabled\": true\n    },\n    \"name-of-other-mcp-server\": {\n      // ...\n    }\n  }\n}\n```\n\nYou can also disable a server by setting `enabled` to `false`. This is useful if you want to temporarily disable a server without removing it from your config.\n\n---\n\n### Local\n\nAdd local MCP servers using `type` to `\"local\"` within the MCP object.\n\n```jsonc title=\"opencode.jsonc\" {15}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"my-local-mcp-server\": {\n      \"type\": \"local\",\n      // Or [\"bun\", \"x\", \"my-mcp-command\"]\n      \"command\": [\"npx\", \"-y\", \"my-mcp-command\"],\n      \"enabled\": true,\n      \"environment\": {\n        \"MY_ENV_VAR\": \"my_env_var_value\"\n      }\n    }\n  }\n}\n```\n\nThe command is how the local MCP server is started. You can also pass in a list of environment variables as well.\n\nFor example, here's how I can add the test\n[`@modelcontextprotocol/server-everything`](https://www.npmjs.com/package/@modelcontextprotocol/server-everything) MCP server.\n\n```jsonc title=\"opencode.jsonc\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"mcp_everything\": {\n      \"type\": \"local\",\n      \"command\": [\"npx\", \"-y\", \"@modelcontextprotocol/server-everything\"],\n    }\n  }\n}\n```\n\nAnd to use it I can add `use the mcp_everything tool` to my prompts.\n\n```txt \"mcp_everything\"\nuse the mcp_everything tool to add the number 3 and 4\n```\n\n#### Options\n\nHere are all the options for configuring a local MCP server.\n\n| Option        | Type    | Required | Description                                           |\n| ------------- | ------- | -------- | ----------------------------------------------------- |\n| `type`        | String  | Y        | Type of MCP server connection, must be `\"local\"`.     |\n| `command`     | Array   | Y        | Command and arguments to run the MCP server.          |\n| `environment` | Object  |          | Environment variables to set when running the server. |\n| `enabled`     | Boolean |          | Enable or disable the MCP server on startup.          |\n\n---\n\n### Remote\n\nAdd remote MCP servers under by setting `type` to `\"remote\"`.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"my-remote-mcp\": {\n      \"type\": \"remote\",\n      \"url\": \"https://my-mcp-server.com\",\n      \"enabled\": true,\n      \"headers\": {\n        \"Authorization\": \"Bearer MY_API_KEY\"\n      }\n    }\n  }\n}\n```\n\nHere the `url` is the URL of the remote MCP server and with the `headers` option you can pass in a list of headers.\n\n#### Options\n\n| Option    | Type    | Required | Description                                        |\n| --------- | ------- | -------- | -------------------------------------------------- |\n| `type`    | String  | Y        | Type of MCP server connection, must be `\"remote\"`. |\n| `url`     | String  | Y        | URL of the remote MCP server.                      |\n| `enabled` | Boolean |          | Enable or disable the MCP server on startup.       |\n| `headers` | Object  |          | Headers to send with the request.                  |\n\n---\n\n## Manage\n\nYour MCPs are available as tools in OpenCode, alongside built-in tools. So you\ncan manage them through the OpenCode config like any other tool.\n\n---\n\n### Global\n\nThis means that you can enable or disable them globally.\n\n```json title=\"opencode.json\" {14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"my-mcp-foo\": {\n      \"type\": \"local\",\n      \"command\": [\"bun\", \"x\", \"my-mcp-command-foo\"]\n    },\n    \"my-mcp-bar\": {\n      \"type\": \"local\",\n      \"command\": [\"bun\", \"x\", \"my-mcp-command-bar\"]\n    }\n  },\n  \"tools\": {\n    \"my-mcp-foo\": false\n  }\n}\n```\n\nWe can also use a glob pattern to disable all matching MCPs.\n\n```json title=\"opencode.json\" {14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"my-mcp-foo\": {\n      \"type\": \"local\",\n      \"command\": [\"bun\", \"x\", \"my-mcp-command-foo\"]\n    },\n    \"my-mcp-bar\": {\n      \"type\": \"local\",\n      \"command\": [\"bun\", \"x\", \"my-mcp-command-bar\"]\n    }\n  },\n  \"tools\": {\n    \"my-mcp*\": false\n  }\n}\n```\n\nHere we are using the glob pattern `my-mcp*` to disable all MCPs.\n\n---\n\n### Per agent\n\nIf you have a large number of MCP servers you may want to only enable them per\nagent and disable them globally. To do this:\n\n1. Disable it as a tool globally.\n2. In your [agent config](/docs/agents#tools) enable the MCP server as a tool.\n\n```json title=\"opencode.json\" {11, 14-18}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"my-mcp\": {\n      \"type\": \"local\",\n      \"command\": [\"bun\", \"x\", \"my-mcp-command\"],\n      \"enabled\": true\n    }\n  },\n  \"tools\": {\n    \"my-mcp*\": false\n  },\n  \"agent\": {\n    \"my-agent\": {\n      \"tools\": {\n        \"my-mcp*\": true\n      }\n    }\n  }\n}\n```\n\n---\n\n#### Glob patterns\n\nThe glob pattern uses simple regex globbing patterns.\n\n- `*` matches zero or more of any character\n- `?` matches exactly one character\n- All other characters match literally\n\n---\n\n## Examples\n\nBelow are examples of some common MCP servers. You can submit a PR if you want to document other servers.\n\n---\n\n### Context7\n\nAdd the [Context7 MCP server](https://github.com/context-labs/mcp-server-context7) to search through docs.\n\n```json title=\"opencode.json\" {4-7}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"remote\",\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n```\n\nIf you have signed up for a free account, you can use your API key and get higher rate-limits.\n\n```json title=\"opencode.json\" {7-9}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"context7\": {\n      \"type\": \"remote\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"{env:CONTEXT7_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\nHere we are assuming that you have the `CONTEXT7_API_KEY` environment variable set.\n\nAdd `use context7` to your prompts to use Context7 MCP server.\n\n```txt \"use context7\"\nConfigure a Cloudflare Worker script to cache JSON API responses for five minutes. use context7\n```\n\nAlternatively, you can add something like this to your\n[AGENTS.md](/docs/rules/).\n\n```md title=\"AGENTS.md\"\nWhen you need to search docs, use `context7` tools.\n```\n\n---\n\n### Grep by Vercel\n\nAdd the [Grep by Vercel](https://github.com/vercel/grep-by-vercel) MCP server to search through code snippets on GitHub.\n\n```json title=\"opencode.json\" {4-7}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"gh_grep\": {\n      \"type\": \"remote\",\n      \"url\": \"https://mcp.grep.app\"\n    }\n  }\n}\n```\n\nSince we named our MCP server `gh_grep`, you can add `use the gh_grep tool` to your prompts to get the agent to use it.\n\n```txt \"use the gh_grep tool\"\nWhat's the right way to set a custom domain in an SST Astro component? use the gh_grep tool\n```\n\nAlternatively, you can add something like this to your\n[AGENTS.md](/docs/rules/).\n\n```md title=\"AGENTS.md\"\nIf you are unsure how to do something, use `gh_grep` to search code examples from github.\n```","src/content/docs/mcp-servers.mdx","8ab4b8aa19044a3e","models",{id:168,data:170,body:176,filePath:177,digest:178,deferredRender:16},{title:171,description:172,editUrl:16,head:173,template:18,sidebar:174,pagefind:16,draft:20},"Models","Configuring an LLM provider and model.",[],{hidden:20,attrs:175},{},"OpenCode uses the [AI SDK](https://ai-sdk.dev/) and [Models.dev](https://models.dev) to support for **75+ LLM providers** and it supports running local models.\n\n---\n\n## Providers\n\nMost popular providers are preloaded by default. If you've added the credentials for a provider through `opencode auth login`, they'll be available when you start OpenCode.\n\nLearn more about [providers](/docs/providers).\n\n---\n\n## Select a model\n\nOnce you've configured your provider you can select the model you want by typing in:\n\n```bash frame=\"none\"\n/models\n```\n\n---\n\n## Recommended models\n\nThere are a lot of models out there, with new models coming out every week.\n\n:::tip\nConsider using one of the models we recommend.\n:::\n\nHowever, there are only a few of them that are good at both generating code and tool calling.\n\nHere are several models, in no particular order, that work well with OpenCode (to name a few):\n\n- GPT 5\n- GPT 5 Codex\n- Claude Sonnet 4.5\n- Claude Sonnet 4\n- Claude Opus 4.1\n- Kimi K2\n- Qwen3 Coder\n- GPT 4.1\n- Gemini 2.5 Pro\n\n---\n\n## Set a default\n\nTo set one of these as the default model, you can set the `model` key in your\nOpenCode config.\n\n```json title=\"opencode.json\" {3}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"model\": \"lmstudio/google/gemma-3n-e4b\"\n}\n```\n\nHere the full ID is `provider_id/model_id`.\n\nIf you've configured a [custom provider](/docs/providers#custom), the `provider_id` is key from the `provider` part of your config, and the `model_id` is the key from `provider.models`.\n\n---\n\n## Configure models\n\nYou can globally configure a model's options through the config.\n\n```jsonc title=\"opencode.jsonc\" {7-12,19-24}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"openai\": {\n      \"models\": {\n        \"gpt-5\": {\n          \"options\": {\n            \"reasoningEffort\": \"high\",\n            \"textVerbosity\": \"low\",\n            \"reasoningSummary\": \"auto\",\n            \"include\": [\"reasoning.encrypted_content\"],\n          },\n        },\n      },\n    },\n    \"anthropic\": {\n      \"models\": {\n        \"claude-sonnet-4-5-20250929\": {\n          \"options\": {\n            \"thinking\": {\n              \"type\": \"enabled\",\n              \"budgetTokens\": 16000,\n            },\n          },\n        },\n      },\n    },\n  },\n}\n```\n\nHere we're configuring global settings for two built-in models: `gpt-5` when accessed via the `openai` provider, and `claude-sonnet-4-20250514` when accessed via the `anthropic` provider.\nThe built-in provider and model names can be found on [Models.dev](https://models.dev).\n\nYou can also configure these options for any agents that you are using. The agent config overrides any global options here. [Learn more](/docs/agents/#additional).\n\nYou can also define custom models that extend built-in ones and can optionally use specific options by referring to their id:\n\n```jsonc title=\"opencode.jsonc\" {6-20}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"opencode\": {\n      \"models\": {\n        \"gpt-5-high\": {\n          \"id\": \"gpt-5\",\n          \"options\": {\n            \"reasoningEffort\": \"high\",\n            \"textVerbosity\": \"low\",\n            \"reasoningSummary\": \"auto\",\n          },\n        },\n        \"gpt-5-low\": {\n          \"id\": \"gpt-5\",\n          \"options\": {\n            \"reasoningEffort\": \"low\",\n            \"textVerbosity\": \"low\",\n            \"reasoningSummary\": \"auto\",\n          },\n        },\n      },\n    },\n  },\n}\n```\n\n---\n\n## Loading models\n\nWhen OpenCode starts up, it checks for models in the following priority order:\n\n1. The `--model` or `-m` command line flag. The format is the same as in the config file: `provider_id/model_id`.\n\n2. The model list in the OpenCode config.\n\n   ```json title=\"opencode.json\"\n   {\n     \"$schema\": \"https://opencode.ai/config.json\",\n     \"model\": \"anthropic/claude-sonnet-4-20250514\"\n   }\n   ```\n\n   The format here is `provider/model`.\n\n3. The last used model.\n\n4. The first model using an internal priority.","src/content/docs/models.mdx","4a8f1c1d51b28123","modes",{id:179,data:181,body:187,filePath:188,digest:189,deferredRender:16},{title:182,description:183,editUrl:16,head:184,template:18,sidebar:185,pagefind:16,draft:20},"Modes","Different modes for different use cases.",[],{hidden:20,attrs:186},{},":::caution\nModes are now configured through the `agent` option in the opencode config. The\n`mode` option is now deprecated. [Learn more](/docs/agents).\n:::\n\nModes in opencode allow you to customize the behavior, tools, and prompts for different use cases.\n\nIt comes with two built-in modes: **build** and **plan**. You can customize\nthese or configure your own through the opencode config.\n\nYou can switch between modes during a session or configure them in your config file.\n\n---\n\n## Built-in\n\nopencode comes with two built-in modes.\n\n---\n\n### Build\n\nBuild is the **default** mode with all tools enabled. This is the standard mode for development work where you need full access to file operations and system commands.\n\n---\n\n### Plan\n\nA restricted mode designed for planning and analysis. In plan mode, the following tools are disabled by default:\n\n- `write` - Cannot create new files\n- `edit` - Cannot modify existing files\n- `patch` - Cannot apply patches\n- `bash` - Cannot execute shell commands\n\nThis mode is useful when you want the AI to analyze code, suggest changes, or create plans without making any actual modifications to your codebase.\n\n---\n\n## Switching\n\nYou can switch between modes during a session using the _Tab_ key. Or your configured `switch_mode` keybind.\n\nSee also: [Formatters](/docs/formatters) for information about code formatting configuration.\n\n---\n\n## Configure\n\nYou can customize the built-in modes or create your own through configuration. Modes can be configured in two ways:\n\n### JSON Configuration\n\nConfigure modes in your `opencode.json` config file:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mode\": {\n    \"build\": {\n      \"model\": \"anthropic/claude-sonnet-4-20250514\",\n      \"prompt\": \"{file:./prompts/build.txt}\",\n      \"tools\": {\n        \"write\": true,\n        \"edit\": true,\n        \"bash\": true\n      }\n    },\n    \"plan\": {\n      \"model\": \"anthropic/claude-haiku-4-20250514\",\n      \"tools\": {\n        \"write\": false,\n        \"edit\": false,\n        \"bash\": false\n      }\n    }\n  }\n}\n```\n\n### Markdown Configuration\n\nYou can also define modes using markdown files. Place them in:\n\n- Global: `~/.config/opencode/mode/`\n- Project: `.opencode/mode/`\n\n```markdown title=\"~/.config/opencode/mode/review.md\"\n---\nmodel: anthropic/claude-sonnet-4-20250514\ntemperature: 0.1\ntools:\n  write: false\n  edit: false\n  bash: false\n---\n\nYou are in code review mode. Focus on:\n\n- Code quality and best practices\n- Potential bugs and edge cases\n- Performance implications\n- Security considerations\n\nProvide constructive feedback without making direct changes.\n```\n\nThe markdown file name becomes the mode name (e.g., `review.md` creates a `review` mode).\n\nLet's look at these configuration options in detail.\n\n---\n\n### Model\n\nUse the `model` config to override the default model for this mode. Useful for using different models optimized for different tasks. For example, a faster model for planning, a more capable model for implementation.\n\n```json title=\"opencode.json\"\n{\n  \"mode\": {\n    \"plan\": {\n      \"model\": \"anthropic/claude-haiku-4-20250514\"\n    }\n  }\n}\n```\n\n---\n\n### Temperature\n\nControl the randomness and creativity of the AI's responses with the `temperature` config. Lower values make responses more focused and deterministic, while higher values increase creativity and variability.\n\n```json title=\"opencode.json\"\n{\n  \"mode\": {\n    \"plan\": {\n      \"temperature\": 0.1\n    },\n    \"creative\": {\n      \"temperature\": 0.8\n    }\n  }\n}\n```\n\nTemperature values typically range from 0.0 to 1.0:\n\n- **0.0-0.2**: Very focused and deterministic responses, ideal for code analysis and planning\n- **0.3-0.5**: Balanced responses with some creativity, good for general development tasks\n- **0.6-1.0**: More creative and varied responses, useful for brainstorming and exploration\n\n```json title=\"opencode.json\"\n{\n  \"mode\": {\n    \"analyze\": {\n      \"temperature\": 0.1,\n      \"prompt\": \"{file:./prompts/analysis.txt}\"\n    },\n    \"build\": {\n      \"temperature\": 0.3\n    },\n    \"brainstorm\": {\n      \"temperature\": 0.7,\n      \"prompt\": \"{file:./prompts/creative.txt}\"\n    }\n  }\n}\n```\n\nIf no temperature is specified, opencode uses model-specific defaults (typically 0 for most models, 0.55 for Qwen models).\n\n---\n\n### Prompt\n\nSpecify a custom system prompt file for this mode with the `prompt` config. The prompt file should contain instructions specific to the mode's purpose.\n\n```json title=\"opencode.json\"\n{\n  \"mode\": {\n    \"review\": {\n      \"prompt\": \"{file:./prompts/code-review.txt}\"\n    }\n  }\n}\n```\n\nThis path is relative to where the config file is located. So this works for\nboth the global opencode config and the project specific config.\n\n---\n\n### Tools\n\nControl which tools are available in this mode with the `tools` config. You can enable or disable specific tools by setting them to `true` or `false`.\n\n```json\n{\n  \"mode\": {\n    \"readonly\": {\n      \"tools\": {\n        \"write\": false,\n        \"edit\": false,\n        \"bash\": false,\n        \"read\": true,\n        \"grep\": true,\n        \"glob\": true\n      }\n    }\n  }\n}\n```\n\nIf no tools are specified, all tools are enabled by default.\n\n---\n\n#### Available tools\n\nHere are all the tools can be controlled through the mode config.\n\n| Tool        | Description             |\n| ----------- | ----------------------- |\n| `bash`      | Execute shell commands  |\n| `edit`      | Modify existing files   |\n| `write`     | Create new files        |\n| `read`      | Read file contents      |\n| `grep`      | Search file contents    |\n| `glob`      | Find files by pattern   |\n| `list`      | List directory contents |\n| `patch`     | Apply patches to files  |\n| `todowrite` | Manage todo lists       |\n| `todoread`  | Read todo lists         |\n| `webfetch`  | Fetch web content       |\n\n---\n\n## Custom modes\n\nYou can create your own custom modes by adding them to the configuration. Here are examples using both approaches:\n\n### Using JSON configuration\n\n```json title=\"opencode.json\" {4-14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mode\": {\n    \"docs\": {\n      \"prompt\": \"{file:./prompts/documentation.txt}\",\n      \"tools\": {\n        \"write\": true,\n        \"edit\": true,\n        \"bash\": false,\n        \"read\": true,\n        \"grep\": true,\n        \"glob\": true\n      }\n    }\n  }\n}\n```\n\n### Using markdown files\n\nCreate mode files in `.opencode/mode/` for project-specific modes or `~/.config/opencode/mode/` for global modes:\n\n```markdown title=\".opencode/mode/debug.md\"\n---\ntemperature: 0.1\ntools:\n  bash: true\n  read: true\n  grep: true\n  write: false\n  edit: false\n---\n\nYou are in debug mode. Your primary goal is to help investigate and diagnose issues.\n\nFocus on:\n\n- Understanding the problem through careful analysis\n- Using bash commands to inspect system state\n- Reading relevant files and logs\n- Searching for patterns and anomalies\n- Providing clear explanations of findings\n\nDo not make any changes to files. Only investigate and report.\n```\n\n```markdown title=\"~/.config/opencode/mode/refactor.md\"\n---\nmodel: anthropic/claude-sonnet-4-20250514\ntemperature: 0.2\ntools:\n  edit: true\n  read: true\n  grep: true\n  glob: true\n---\n\nYou are in refactoring mode. Focus on improving code quality without changing functionality.\n\nPriorities:\n\n- Improve code readability and maintainability\n- Apply consistent naming conventions\n- Reduce code duplication\n- Optimize performance where appropriate\n- Ensure all tests continue to pass\n```\n\n---\n\n### Use cases\n\nHere are some common use cases for different modes.\n\n- **Build mode**: Full development work with all tools enabled\n- **Plan mode**: Analysis and planning without making changes\n- **Review mode**: Code review with read-only access plus documentation tools\n- **Debug mode**: Focused on investigation with bash and read tools enabled\n- **Docs mode**: Documentation writing with file operations but no system commands\n\nYou might also find different models are good for different use cases.","src/content/docs/modes.mdx","f9174c1810849089","permissions",{id:190,data:192,body:198,filePath:199,digest:200,deferredRender:16},{title:193,description:194,editUrl:16,head:195,template:18,sidebar:196,pagefind:16,draft:20},"Permissions","Control which actions require approval to run.",[],{hidden:20,attrs:197},{},"By default, OpenCode **allows all operations** without requiring explicit approval. You can configure this using the `permission` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"edit\": \"allow\",\n    \"bash\": \"ask\",\n    \"webfetch\": \"deny\"\n  }\n}\n```\n\nThis lets you configure granular controls for the `edit`, `bash`, and `webfetch` tools.\n\n- `\"ask\"` — Prompt for approval before running the tool\n- `\"allow\"` — Allow all operations without approval\n- `\"deny\"` — Disable the tool\n\n---\n\n## Tools\n\nCurrently, the permissions for the `edit`, `bash`, and `webfetch` tools can be configured through the `permission` option.\n\n---\n\n### edit\n\nUse the `permission.edit` key to control whether file editing operations require user approval.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"edit\": \"ask\"\n  }\n}\n```\n\n---\n\n### bash\n\nYou can use the `permission.bash` key to control whether bash commands as a\nwhole need user approval.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"bash\": \"ask\"\n  }\n}\n```\n\nOr, you can target specific commands and set it to `allow`, `ask`, or `deny`.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"bash\": {\n      \"git push\": \"ask\",\n      \"git status\": \"allow\",\n      \"git diff\": \"allow\",\n      \"npm run build\": \"allow\",\n      \"ls\": \"allow\",\n      \"pwd\": \"allow\"\n    }\n  }\n}\n```\n\n---\n\n#### Wildcards\n\nYou can also use wildcards to manage permissions for specific bash commands.\n\n:::tip\nYou can use wildcards to manage permissions for specific bash commands.\n:::\n\nFor example, **disable all** Terraform commands.\n\n```json title=\"opencode.json\" {5}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"bash\": {\n      \"terraform *\": \"deny\"\n    }\n  }\n}\n```\n\nYou can also use the `*` wildcard to manage permissions for all commands. For\nexample, **deny all commands** except a couple of specific ones.\n\n```json title=\"opencode.json\" {5}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"bash\": {\n      \"*\": \"deny\",\n      \"pwd\": \"allow\",\n      \"git status\": \"ask\"\n    }\n  }\n}\n```\n\nHere a specific rule can override the `*` wildcard.\n\n---\n\n##### Glob patterns\n\nThe wildcard uses simple regex globbing patterns.\n\n- `*` matches zero or more of any character\n- `?` matches exactly one character\n- All other characters match literally\n\n---\n\n### webfetch\n\nUse the `permission.webfetch` key to control whether the LLM can fetch web pages.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"webfetch\": \"ask\"\n  }\n}\n```\n\n---\n\n## Agents\n\nYou can also configure permissions per agent. Where the agent specific config\noverrides the global config. [Learn more](/docs/agents#permissions) about agent permissions.\n\n```json title=\"opencode.json\" {3-7,10-14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"permission\": {\n    \"bash\": {\n      \"git push\": \"ask\"\n    }\n  },\n  \"agent\": {\n    \"build\": {\n      \"permission\": {\n        \"bash\": {\n          \"git push\": \"allow\"\n        }\n      }\n    }\n  }\n}\n```\n\nFor example, here the `build` agent overrides the global `bash` permission to\nallow `git push` commands.\n\nYou can also configure permissions for agents in Markdown.\n\n```markdown title=\"~/.config/opencode/agent/review.md\"\n---\ndescription: Code review without edits\nmode: subagent\npermission:\n  edit: deny\n  bash: ask\n  webfetch: deny\n---\n\nOnly analyze code and suggest changes.\n```","src/content/docs/permissions.mdx","cdf1fe8059ce13a8","plugins",{id:201,data:203,body:209,filePath:210,digest:211,deferredRender:16},{title:204,description:205,editUrl:16,head:206,template:18,sidebar:207,pagefind:16,draft:20},"Plugins","Write your own plugins to extend OpenCode.",[],{hidden:20,attrs:208},{},"Plugins allow you to extend OpenCode by hooking into various events and customizing behavior. You can create plugins to add new features, integrate with external services, or modify OpenCode's default behavior.\n\n---\n\n## Create a plugin\n\nA plugin is a **JavaScript/TypeScript module** that exports one or more plugin\nfunctions. Each function receives a context object and returns a hooks object.\n\n---\n\n### Location\n\nPlugins are loaded from:\n\n1. `.opencode/plugin` directory either in your project\n2. Or, globally in `~/.config/opencode/plugin`\n\n---\n\n### Basic structure\n\n```js title=\".opencode/plugin/example.js\"\nexport const MyPlugin = async ({ project, client, $, directory, worktree }) => {\n  console.log(\"Plugin initialized!\")\n\n  return {\n    // Hook implementations go here\n  }\n}\n```\n\nThe plugin function receives:\n\n- `project`: The current project information.\n- `directory`: The current working directory.\n- `worktree`: The git worktree path.\n- `client`: An opencode SDK client for interacting with the AI.\n- `$`: Bun's [shell API](https://bun.com/docs/runtime/shell) for executing commands.\n\n---\n\n### TypeScript support\n\nFor TypeScript plugins, you can import types from the plugin package:\n\n```ts title=\"my-plugin.ts\" {1}\nimport type { Plugin } from \"@opencode-ai/plugin\"\n\nexport const MyPlugin: Plugin = async ({ project, client, $, directory, worktree }) => {\n  return {\n    // Type-safe hook implementations\n  }\n}\n```\n\n---\n\n## Examples\n\nHere are some examples of plugins you can use to extend opencode.\n\n---\n\n### Send notifications\n\nSend notifications when certain events occur:\n\n```js title=\".opencode/plugin/notification.js\"\nexport const NotificationPlugin = async ({ project, client, $, directory, worktree }) => {\n  return {\n    event: async ({ event }) => {\n      // Send notification on session completion\n      if (event.type === \"session.idle\") {\n        await $`osascript -e 'display notification \"Session completed!\" with title \"opencode\"'`\n      }\n    },\n  }\n}\n```\n\nWe are using `osascript` to run AppleScript on macOS. Here we are using it to send notifications.\n\n---\n\n### .env protection\n\nPrevent opencode from reading `.env` files:\n\n```javascript title=\".opencode/plugin/env-protection.js\"\nexport const EnvProtection = async ({ project, client, $, directory, worktree }) => {\n  return {\n    \"tool.execute.before\": async (input, output) => {\n      if (input.tool === \"read\" && output.args.filePath.includes(\".env\")) {\n        throw new Error(\"Do not read .env files\")\n      }\n    },\n  }\n}\n```\n\n---\n\n### Custom tools\n\nPlugins can also add custom tools to opencode:\n\n```ts title=\".opencode/plugin/custom-tools.ts\"\nimport { type Plugin, tool } from \"@opencode-ai/plugin\"\n\nexport const CustomToolsPlugin: Plugin = async (ctx) => {\n  return {\n    tool: {\n      mytool: tool({\n        description: \"This is a custom tool\",\n        args: {\n          foo: tool.schema.string(),\n        },\n        async execute(args, ctx) {\n          return `Hello ${args.foo}!`\n        },\n      }),\n    },\n  }\n}\n```\n\nThe `tool` helper creates a custom tool that opencode can call. It takes a Zod schema function and returns a tool definition with:\n\n- `description`: What the tool does\n- `args`: Zod schema for the tool's arguments\n- `execute`: Function that runs when the tool is called\n\nYour custom tools will be available to opencode alongside built-in tools.","src/content/docs/plugins.mdx","898ed5b4ff528110","providers",{id:212,data:214,body:220,filePath:221,digest:222,deferredRender:16},{title:215,description:216,editUrl:16,head:217,template:18,sidebar:218,pagefind:16,draft:20},"Providers","Using any LLM provider in OpenCode.",[],{hidden:20,attrs:219},{},"import config from \"../../../config.mjs\"\nexport const console = config.console\n\nOpenCode uses the [AI SDK](https://ai-sdk.dev/) and [Models.dev](https://models.dev) to support for **75+ LLM providers** and it supports running local models.\n\nTo add a provider you need to:\n\n1. Add the API keys for the provider using `opencode auth login`.\n2. Configure the provider in your OpenCode config.\n\n---\n\n### Credentials\n\nWhen you add a provider's API keys with `opencode auth login`, they are stored\nin `~/.local/share/opencode/auth.json`.\n\n---\n\n### Config\n\nYou can customize the providers through the `provider` section in your OpenCode\nconfig.\n\n---\n\n#### Base URL\n\nYou can customize the base URL for any provider by setting the `baseURL` option. This is useful when using proxy services or custom endpoints.\n\n```json title=\"opencode.json\" {6}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"anthropic\": {\n      \"options\": {\n        \"baseURL\": \"https://api.anthropic.com/v1\"\n      }\n    }\n  }\n}\n```\n\n---\n\n## OpenCode Zen\n\nOpenCode Zen is a list of models provided by the OpenCode team that have been\ntested and verified to work well with OpenCode. [Learn more](/docs/zen).\n\n:::tip\nIf you are new, we recommend starting with OpenCode Zen.\n:::\n\n1. Run `opencode auth login`, select opencode, and head to [opencode.ai/auth](https://opencode.ai/auth).\n2. Sign in, add your billing details, and copy your API key.\n3. Paste your API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  opencode\n   │\n   ●  Create an api key at https://opencode.ai/auth\n   │\n   ◆  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run `/models` in the TUI to see the list of models we recommend.\n\nIt works like any other provider in OpenCode. And is completely optional to use\nit.\n\n---\n\n## Directory\n\nLet's look at some of the providers in detail. If you'd like to add a provider to the\nlist, feel free to open a PR.\n\n:::note\nDon't see a provider here? Submit a PR.\n:::\n\n---\n\n### Amazon Bedrock\n\nTo use Amazon Bedrock with OpenCode:\n\n1. Head over to the **Model catalog** in the Amazon Bedrock console and request\n   access to the models you want.\n\n   :::tip\n   You need to have access to the model you want in Amazon Bedrock.\n   :::\n\n1. You'll need either to set one of the following environment variables:\n   - `AWS_ACCESS_KEY_ID`: You can get this by creating an IAM user and generating\n     an access key for it.\n   - `AWS_PROFILE`: First login through AWS IAM Identity Center (or AWS SSO) using\n     `aws sso login`. Then get the name of the profile you want to use.\n   - `AWS_BEARER_TOKEN_BEDROCK`: You can generate a long-term API key from the\n     Amazon Bedrock console.\n\n   Once you have one of the above, set it while running opencode.\n\n   ```bash\n   AWS_ACCESS_KEY_ID=XXX opencode\n   ```\n\n   Or add it to a `.env` file in the project root.\n\n   ```bash title=\".env\"\n   AWS_ACCESS_KEY_ID=XXX\n   ```\n\n   Or add it to your bash profile.\n\n   ```bash title=\"~/.bash_profile\"\n   export AWS_ACCESS_KEY_ID=XXX\n   ```\n\n1. Run the `/models` command to select the model you want.\n\n---\n\n### Anthropic\n\nWe recommend signing up for [Claude Pro](https://www.anthropic.com/news/claude-pro) or [Max](https://www.anthropic.com/max), it's the most cost-effective way to use opencode.\n\nOnce you've signed up, run `opencode auth login` and select Anthropic.\n\n```bash\n$ opencode auth login\n\n┌  Add credential\n│\n◆  Select provider\n│  ● Anthropic\n│  ...\n└\n```\n\nHere you can select the **Claude Pro/Max** option and it'll open your browser\nand ask you to authenticate.\n\n```bash\n$ opencode auth login\n┌  Add credential\n│\n◇  Select provider\n│  Anthropic\n│\n◆  Login method\n│  ● Claude Pro/Max\n│  ○ Create API Key\n│  ○ Manually enter API Key\n└\n```\n\nNow all the the Anthropic models should be available when you use the `/models` command.\n\n##### Using API keys\n\nYou can also select **Create API Key** if you don't have a Pro/Max subscription. It'll also open your browser and ask you to login to Anthropic and give you a code you can paste in your terminal.\n\nOr if you already have an API key, you can select **Manually enter API Key** and paste it in your terminal.\n\n---\n\n### Azure OpenAI\n\n1. Head over to the [Azure portal](https://portal.azure.com/) and create an **Azure OpenAI** resource. You'll need:\n   - **Resource name**: This becomes part of your API endpoint (`https://RESOURCE_NAME.openai.azure.com/`)\n   - **API key**: Either `KEY 1` or `KEY 2` from your resource\n\n2. Go to [Azure AI Foundry](https://ai.azure.com/) and deploy a model.\n\n   :::note\n   The deployment name must match the model name for opencode to work properly.\n   :::\n\n3. Run `opencode auth login` and select **Azure**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Azure\n   │  ...\n   └\n   ```\n\n4. Enter your API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Azure\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n5. Set your resource name as an environment variable:\n\n   ```bash\n   AZURE_RESOURCE_NAME=XXX opencode\n   ```\n\n   Or add it to a `.env` file in the project root:\n\n   ```bash title=\".env\"\n   AZURE_RESOURCE_NAME=XXX\n   ```\n\n   Or add it to your bash profile:\n\n   ```bash title=\"~/.bash_profile\"\n   export AZURE_RESOURCE_NAME=XXX\n   ```\n\n6. Run the `/models` command to select your deployed model.\n\n---\n\n### Cerebras\n\n1. Head over to the [Cerebras console](https://inference.cerebras.ai/), create an account, and generate an API key.\n\n2. Run `opencode auth login` and select **Cerebras**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Cerebras\n   │  ...\n   └\n   ```\n\n3. Enter your Cerebras API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Cerebras\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a model like _Qwen 3 Coder 480B_.\n\n---\n\n### DeepSeek\n\n1. Head over to the [DeepSeek console](https://platform.deepseek.com/), create an account, and click **Create new API key**.\n\n2. Run `opencode auth login` and select **DeepSeek**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● DeepSeek\n   │  ...\n   └\n   ```\n\n3. Enter your DeepSeek API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  DeepSeek\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a DeepSeek model like _DeepSeek Reasoner_.\n\n---\n\n### Fireworks AI\n\n1. Head over to the [Fireworks AI console](https://app.fireworks.ai/), create an account, and click **Create API Key**.\n\n2. Run `opencode auth login` and select **Fireworks AI**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Fireworks AI\n   │  ...\n   └\n   ```\n\n3. Enter your Fireworks AI API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Fireworks AI\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a model like _Kimi K2 Instruct_.\n\n---\n\n### GitHub Copilot\n\nTo use your GitHub Copilot subscription with opencode:\n\n:::note\nSome models might need a [Pro+\nsubscription](https://github.com/features/copilot/plans) to use.\n\nSome models need to be manually enabled in your [GitHub Copilot settings](https://docs.github.com/en/copilot/how-tos/use-ai-models/configure-access-to-ai-models#setup-for-individual-use).\n:::\n\n1. Run `opencode auth login` and select GitHub Copilot.\n\n   ```bash\n   $ opencode auth login\n   ┌  Add credential\n\n   │\n   ◇  Select provider\n   │  GitHub Copilot\n   │\n   ◇   ──────────────────────────────────────────────╮\n   │                                                 │\n   │  Please visit: https://github.com/login/device  │\n   │  Enter code: 8F43-6FCF                          │\n   │                                                 │\n   ├─────────────────────────────────────────────────╯\n   │\n   ◓  Waiting for authorization...\n   ```\n\n2. Navigate to [github.com/login/device](https://github.com/login/device) and enter the code.\n\n3. Now run the `/models` command to select the model you want.\n\n---\n\n### Groq\n\n1. Head over to the [Groq console](https://console.groq.com/), click **Create API Key**, and copy the key.\n\n2. Run `opencode auth login` and select Groq.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Groq\n   │  ...\n   └\n   ```\n\n3. Enter the API key for the provider.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Groq\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select the one you want.\n\n---\n\n### LM Studio\n\nYou can configure opencode to use local models through LM Studio.\n\n```json title=\"opencode.json\" \"lmstudio\" {5, 6, 8, 10-14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"lmstudio\": {\n      \"npm\": \"@ai-sdk/openai-compatible\",\n      \"name\": \"LM Studio (local)\",\n      \"options\": {\n        \"baseURL\": \"http://127.0.0.1:1234/v1\"\n      },\n      \"models\": {\n        \"google/gemma-3n-e4b\": {\n          \"name\": \"Gemma 3n-e4b (local)\"\n        }\n      }\n    }\n  }\n}\n```\n\nIn this example:\n\n- `lmstudio` is the custom provider ID. This can be any string you want.\n- `npm` specifies the package to use for this provider. Here, `@ai-sdk/openai-compatible` is used for any OpenAI-compatible API.\n- `name` is the display name for the provider in the UI.\n- `options.baseURL` is the endpoint for the local server.\n- `models` is a map of model IDs to their configurations. The model name will be displayed in the model selection list.\n\n---\n\n### Moonshot AI\n\nTo use Kimi K2 from Moonshot AI:\n\n1. Head over to the [Moonshot AI console](https://platform.moonshot.ai/console), create an account, and click **Create API key**.\n\n2. Run `opencode auth login` and select **Moonshot AI**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ...\n   │  ● Moonshot AI\n   └\n   ```\n\n3. Enter your Moonshot API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Moonshot AI\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select _Kimi K2_.\n\n---\n\n### Ollama\n\nYou can configure opencode to use local models through Ollama.\n\n```json title=\"opencode.json\" \"ollama\" {5, 6, 8, 10-14}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"ollama\": {\n      \"npm\": \"@ai-sdk/openai-compatible\",\n      \"name\": \"Ollama (local)\",\n      \"options\": {\n        \"baseURL\": \"http://localhost:11434/v1\"\n      },\n      \"models\": {\n        \"llama2\": {\n          \"name\": \"Llama 2\"\n        }\n      }\n    }\n  }\n}\n```\n\nIn this example:\n\n- `ollama` is the custom provider ID. This can be any string you want.\n- `npm` specifies the package to use for this provider. Here, `@ai-sdk/openai-compatible` is used for any OpenAI-compatible API.\n- `name` is the display name for the provider in the UI.\n- `options.baseURL` is the endpoint for the local server.\n- `models` is a map of model IDs to their configurations. The model name will be displayed in the model selection list.\n\n:::tip\nIf tool calls aren't working, try increasing `num_ctx` in Ollama. Start around 16k - 32k.\n:::\n\n---\n\n### OpenAI\n\n1. Head over to the [OpenAI Platform console](https://platform.openai.com/api-keys), click **Create new secret key**, and copy the key.\n\n2. Run `opencode auth login` and select OpenAI.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● OpenAI\n   │  ...\n   └\n   ```\n\n3. Enter the API key for the provider.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  OpenAI\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select the one you want.\n\n---\n\n### OpenCode Zen\n\nOpenCode Zen is a list of tested and verified models provided by the OpenCode team. [Learn more](/docs/zen).\n\n1. Sign in to **<a href={console}>OpenCode Zen</a>** and click **Create API Key**.\n\n2. Run `opencode auth login` and select **OpenCode Zen**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● OpenCode Zen\n   │  ...\n   └\n   ```\n\n3. Enter your OpenCode API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  OpenCode Zen\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a model like _Qwen 3 Coder 480B_.\n\n---\n\n### OpenRouter\n\n1. Head over to the [OpenRouter dashboard](https://openrouter.ai/settings/keys), click **Create API Key**, and copy the key.\n\n2. Run `opencode auth login` and select OpenRouter.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● OpenRouter\n   │  ○ Anthropic\n   │  ○ Google\n   │  ...\n   └\n   ```\n\n3. Enter the API key for the provider.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  OpenRouter\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Many OpenRouter models are preloaded by default, run the `/models` command to select the one you want.\n\n   You can also add additional models through your opencode config.\n\n   ```json title=\"opencode.json\" {6}\n   {\n     \"$schema\": \"https://opencode.ai/config.json\",\n     \"provider\": {\n       \"openrouter\": {\n         \"models\": {\n           \"somecoolnewmodel\": {}\n         }\n       }\n     }\n   }\n   ```\n\n5. You can also customize them through your opencode config. Here's an example of specifying a provider\n\n   ```json title=\"opencode.json\"\n   {\n     \"$schema\": \"https://opencode.ai/config.json\",\n     \"provider\": {\n       \"openrouter\": {\n         \"models\": {\n           \"moonshotai/kimi-k2\": {\n             \"options\": {\n               \"provider\": {\n                 \"order\": [\"baseten\"],\n                 \"allow_fallbacks\": false\n               }\n             }\n           }\n         }\n       }\n     }\n   }\n   ```\n\n---\n\n### Together AI\n\n1. Head over to the [Together AI console](https://api.together.ai), create an account, and click **Add Key**.\n\n2. Run `opencode auth login` and select **Together AI**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Together AI\n   │  ...\n   └\n   ```\n\n3. Enter your Together AI API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Together AI\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a model like _Kimi K2 Instruct_.\n\n---\n\n### xAI\n\nFor a limited time, you can use xAI's Grok Code for free with opencode.\n\n:::tip\nGrok Code is available for free for a limited time on opencode.\n:::\n\n1. Make sure you are on the latest version of opencode.\n\n2. Run the `/models` command and select **Grok Code Free**.\n\nAs a part of the trial period, the xAI team will be using the request logs to\nmonitor and improve Grok Code.\n\n---\n\n### Z.AI\n\n1. Head over to the [Z.AI API console](https://z.ai/manage-apikey/apikey-list), create an account, and click **Create a new API key**.\n\n2. Run `opencode auth login` and select **Z.AI**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Z.AI\n   │  ...\n   └\n   ```\n\n   If you are subscribed to the **GLM Coding Plan**, select **Z.AI Coding Plan**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ● Z.AI Coding Plan\n   │  ...\n   └\n   ```\n\n3. Enter your Z.AI API key.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Select provider\n   │  Z.AI\n   │\n   ◇  Enter your API key\n   │  _\n   └\n   ```\n\n4. Run the `/models` command to select a model like _GLM-4.5_.\n\n---\n\n## Custom provider\n\nTo add any **OpenAI-compatible** provider that's not listed in `opencode auth login`:\n\n:::tip\nYou can use any OpenAI-compatible provider with opencode. Most modern AI providers offer OpenAI-compatible APIs.\n:::\n\n1. Run `opencode auth login` and scroll down to **Other**.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◆  Select provider\n   │  ...\n   │  ● Other\n   └\n   ```\n\n2. Enter a unique ID for the provider.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ◇  Enter provider id\n   │  myprovider\n   └\n   ```\n\n   :::note\n   Choose a memorable ID, you'll use this in your config file.\n   :::\n\n3. Enter your API key for the provider.\n\n   ```bash\n   $ opencode auth login\n\n   ┌  Add credential\n   │\n   ▲  This only stores a credential for myprovider - you will need configure it in opencode.json, check the docs for examples.\n   │\n   ◇  Enter your API key\n   │  sk-...\n   └\n   ```\n\n4. Create or update your `opencode.json` file in your project directory:\n\n   ```json title=\"opencode.json\" \"\"myprovider\"\" {5-15}\n   {\n     \"$schema\": \"https://opencode.ai/config.json\",\n     \"provider\": {\n       \"myprovider\": {\n         \"npm\": \"@ai-sdk/openai-compatible\",\n         \"name\": \"My AI ProviderDisplay Name\",\n         \"options\": {\n           \"baseURL\": \"https://api.myprovider.com/v1\"\n         },\n         \"models\": {\n           \"my-model-name\": {\n             \"name\": \"My Model Display Name\"\n           }\n         }\n       }\n     }\n   }\n   ```\n\n   Here are the configuration options:\n   - **npm**: AI SDK package to use, `@ai-sdk/openai-compatible` for OpenAI-compatible providers\n   - **name**: Display name in UI.\n   - **models**: Available models.\n   - **options.baseURL**: API endpoint URL.\n   - **options.apiKey**: Optionally set the API key, if not using auth.\n   - **options.headers**: Optionally set custom headers.\n\n   More on the advanced options in the example below.\n\n5. Run the `/models` command and your custom provider and models will appear in the selection list.\n\n---\n\n##### Example\n\nHere's an example setting the `apiKey` and `headers` options.\n\n```json title=\"opencode.json\" {9,11}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"provider\": {\n    \"myprovider\": {\n      \"npm\": \"@ai-sdk/openai-compatible\",\n      \"name\": \"My AI ProviderDisplay Name\",\n      \"options\": {\n        \"baseURL\": \"https://api.myprovider.com/v1\",\n        \"apiKey\": \"{env:ANTHROPIC_API_KEY}\",\n        \"headers\": {\n          \"Authorization\": \"Bearer custom-token\"\n        }\n      },\n      \"models\": {\n        \"my-model-name\": {\n          \"name\": \"My Model Display Name\"\n        }\n      }\n    }\n  }\n}\n```\n\nWe are setting the `apiKey` using the `env` variable syntax, [learn more](/docs/config#env-vars).\n\n---\n\n## Troubleshooting\n\nIf you are having trouble with configuring a provider, check the following:\n\n1. **Check the auth setup**: Run `opencode auth list` to see if the credentials\n   for the provider are added to your config.\n\n   This doesn't apply to providers like Amazon Bedrock, that rely on environment variables for their auth.\n\n2. For custom providers, check the opencode config and:\n   - Make sure the provider ID used in `opencode auth login` matches the ID in your opencode config.\n   - The right npm package is used for the provider. For example, use `@ai-sdk/cerebras` for Cerebras. And for all other OpenAI-compatible providers, use `@ai-sdk/openai-compatible`.\n   - Check correct API endpoint is used in the `options.baseURL` field.","src/content/docs/providers.mdx","d1e17b78c443f688","rules",{id:223,data:225,body:231,filePath:232,digest:233,deferredRender:16},{title:226,description:227,editUrl:16,head:228,template:18,sidebar:229,pagefind:16,draft:20},"Rules","Set custom instructions for opencode.",[],{hidden:20,attrs:230},{},"You can provide custom instructions to opencode by creating an `AGENTS.md` file. This is similar to `CLAUDE.md` or Cursor's rules. It contains instructions that will be included in the LLM's context to customize its behavior for your specific project.\n\n---\n\n## Initialize\n\nTo create a new `AGENTS.md` file, you can run the `/init` command in opencode.\n\n:::tip\nYou should commit your project's `AGENTS.md` file to Git.\n:::\n\nThis will scan your project and all its contents to understand what the project is about and generate an `AGENTS.md` file with it. This helps opencode to navigate the project better.\n\nIf you have an existing `AGENTS.md` file, this will try to add to it.\n\n---\n\n## Example\n\nYou can also just create this file manually. Here's an example of some things you can put into an `AGENTS.md` file.\n\n```markdown title=\"AGENTS.md\"\n# SST v3 Monorepo Project\n\nThis is an SST v3 monorepo with TypeScript. The project uses bun workspaces for package management.\n\n## Project Structure\n\n- `packages/` - Contains all workspace packages (functions, core, web, etc.)\n- `infra/` - Infrastructure definitions split by service (storage.ts, api.ts, web.ts)\n- `sst.config.ts` - Main SST configuration with dynamic imports\n\n## Code Standards\n\n- Use TypeScript with strict mode enabled\n- Shared code goes in `packages/core/` with proper exports configuration\n- Functions go in `packages/functions/`\n- Infrastructure should be split into logical files in `infra/`\n\n## Monorepo Conventions\n\n- Import shared modules using workspace names: `@my-app/core/example`\n```\n\nWe are adding project-specific instructions here and this will be shared across your team.\n\n---\n\n## Types\n\nopencode also supports reading the `AGENTS.md` file from multiple locations. And this serves different purposes.\n\n### Project\n\nThe ones we have seen above, where the `AGENTS.md` is placed in the project root, are project-specific rules. These only apply when you are working in this directory or its sub-directories.\n\n### Global\n\nYou can also have global rules in a `~/.config/opencode/AGENTS.md` file. This gets applied across all opencode sessions.\n\nSince this isn't committed to Git or shared with your team, we recommend using this to specify any personal rules that the LLM should follow.\n\n---\n\n## Precedence\n\nSo when opencode starts, it looks for:\n\n1. **Local files** by traversing up from the current directory\n2. **Global file** by checking `~/.config/opencode/AGENTS.md`\n\nIf you have both global and project-specific rules, opencode will combine them together.\n\n---\n\n## Custom Instructions\n\nYou can specify custom instruction files in your `opencode.json` or the global `~/.config/opencode/opencode.json`. This allows you and your team to reuse existing rules rather than having to duplicate them to AGENTS.md.\n\nExample:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"instructions\": [\"CONTRIBUTING.md\", \"docs/guidelines.md\", \".cursor/rules/*.md\"]\n}\n```\n\nAll instruction files are combined with your `AGENTS.md` files.\n\n---\n\n## Referencing External Files\n\nWhile opencode doesn't automatically parse file references in `AGENTS.md`, you can achieve similar functionality in two ways:\n\n### Using opencode.json\n\nThe recommended approach is to use the `instructions` field in `opencode.json`:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"instructions\": [\"docs/development-standards.md\", \"test/testing-guidelines.md\", \"packages/*/AGENTS.md\"]\n}\n```\n\n### Manual Instructions in AGENTS.md\n\nYou can teach opencode to read external files by providing explicit instructions in your `AGENTS.md`. Here's a practical example:\n\n```markdown title=\"AGENTS.md\"\n# TypeScript Project Rules\n\n## External File Loading\n\nCRITICAL: When you encounter a file reference (e.g., @rules/general.md), use your Read tool to load it on a need-to-know basis. They're relevant to the SPECIFIC task at hand.\n\nInstructions:\n\n- Do NOT preemptively load all references - use lazy loading based on actual need\n- When loaded, treat content as mandatory instructions that override defaults\n- Follow references recursively when needed\n\n## Development Guidelines\n\nFor TypeScript code style and best practices: @docs/typescript-guidelines.md\nFor React component architecture and hooks patterns: @docs/react-patterns.md\nFor REST API design and error handling: @docs/api-standards.md\nFor testing strategies and coverage requirements: @test/testing-guidelines.md\n\n## General Guidelines\n\nRead the following file immediately as it's relevant to all workflows: @rules/general-guidelines.md.\n```\n\nThis approach allows you to:\n\n- Create modular, reusable rule files\n- Share rules across projects via symlinks or git submodules\n- Keep AGENTS.md concise while referencing detailed guidelines\n- Ensure opencode loads files only when needed for the specific task\n\n:::tip\nFor monorepos or projects with shared standards, using `opencode.json` with glob patterns (like `packages/*/AGENTS.md`) is more maintainable than manual instructions.\n:::","src/content/docs/rules.mdx","3498b6ea3a8038ee","sdk",{id:234,data:236,body:242,filePath:243,digest:244,deferredRender:16},{title:237,description:238,editUrl:16,head:239,template:18,sidebar:240,pagefind:16,draft:20},"SDK","Type-safe JS client for opencode server.",[],{hidden:20,attrs:241},{},"import config from \"../../../config.mjs\"\nexport const typesUrl = `${config.github}/blob/dev/packages/sdk/js/src/gen/types.gen.ts`\n\nThe opencode JS/TS SDK provides a type-safe client for interacting with the server.\nUse it to build integrations and control opencode programmatically.\n\n[Learn more](/docs/server) about how the server works.\n\n---\n\n## Install\n\nInstall the SDK from npm:\n\n```bash\nnpm install @opencode-ai/sdk\n```\n\n---\n\n## Create client\n\nCreate an instance of opencode:\n\n```javascript\nimport { createOpencode } from \"@opencode-ai/sdk\"\n\nconst { client } = await createOpencode()\n```\n\nThis starts both a server and a client\n\n#### Options\n\n| Option          | Type       | Description                      | Default                 |\n| --------------- | ---------- | -------------------------------- | ----------------------- |\n| `baseUrl`       | `string`   | URL of the server                | `http://localhost:4096` |\n| `fetch`         | `function` | Custom fetch implementation      | `globalThis.fetch`      |\n| `parseAs`       | `string`   | Response parsing method          | `auto`                  |\n| `responseStyle` | `string`   | Return style: `data` or `fields` | `fields`                |\n| `throwOnError`  | `boolean`  | Throw errors instead of return   | `false`                 |\n\n---\n\n## Config\n\nYou can pass a configuration object to customize behavior. The instance still picks up your `opencode.json`, but you can override or add configuration inline:\n\n```javascript\nimport { createOpencode } from \"@opencode-ai/sdk\"\n\nconst opencode = await createOpencode({\n  hostname: \"127.0.0.1\",\n  port: 4096,\n  config: {\n    model: \"anthropic/claude-3-5-sonnet-20241022\",\n  },\n})\n\nconsole.log(`Server running at ${opencode.server.url}`)\n\nopencode.server.close()\n```\n\n## Client only\n\nIf you aready have a running instance of opencode, you can create a client instance to connect to it:\n\n```javascript\nimport { createOpencodeClient } from \"@opencode-ai/sdk\"\n\nconst client = createOpencodeClient({\n  baseUrl: \"http://localhost:4096\",\n})\n```\n\n#### Options\n\n| Option     | Type          | Description                    | Default     |\n| ---------- | ------------- | ------------------------------ | ----------- |\n| `hostname` | `string`      | Server hostname                | `127.0.0.1` |\n| `port`     | `number`      | Server port                    | `4096`      |\n| `signal`   | `AbortSignal` | Abort signal for cancellation  | `undefined` |\n| `timeout`  | `number`      | Timeout in ms for server start | `5000`      |\n| `config`   | `Config`      | Configuration object           | `{}`        |\n\n---\n\n## Types\n\nThe SDK includes TypeScript definitions for all API types. Import them directly:\n\n```typescript\nimport type { Session, Message, Part } from \"@opencode-ai/sdk\"\n```\n\nAll types are generated from the server's OpenAPI specification and available in the <a href={typesUrl}>types file</a>.\n\n---\n\n## Errors\n\nThe SDK can throw errors that you can catch and handle:\n\n```typescript\ntry {\n  await client.session.get({ path: { id: \"invalid-id\" } })\n} catch (error) {\n  console.error(\"Failed to get session:\", (error as Error).message)\n}\n```\n\n---\n\n## APIs\n\nThe SDK exposes all server APIs through a type-safe client.\n\n---\n\n### App\n\n| Method         | Description               | Response                                    |\n| -------------- | ------------------------- | ------------------------------------------- |\n| `app.log()`    | Write a log entry         | `boolean`                                   |\n| `app.agents()` | List all available agents | <a href={typesUrl}><code>Agent[]</code></a> |\n\n---\n\n#### Examples\n\n```javascript\n// Write a log entry\nawait client.app.log({\n  body: {\n    service: \"my-app\",\n    level: \"info\",\n    message: \"Operation completed\",\n  },\n})\n\n// List available agents\nconst agents = await client.app.agents()\n```\n\n---\n\n### Project\n\n| Method              | Description         | Response                                      |\n| ------------------- | ------------------- | --------------------------------------------- |\n| `project.list()`    | List all projects   | <a href={typesUrl}><code>Project[]</code></a> |\n| `project.current()` | Get current project | <a href={typesUrl}><code>Project</code></a>   |\n\n---\n\n#### Examples\n\n```javascript\n// List all projects\nconst projects = await client.project.list()\n\n// Get current project\nconst currentProject = await client.project.current()\n```\n\n---\n\n### Path\n\n| Method       | Description      | Response                                 |\n| ------------ | ---------------- | ---------------------------------------- |\n| `path.get()` | Get current path | <a href={typesUrl}><code>Path</code></a> |\n\n---\n\n#### Examples\n\n```javascript\n// Get current path information\nconst pathInfo = await client.path.get()\n```\n\n---\n\n### Config\n\n| Method               | Description                       | Response                                                                                              |\n| -------------------- | --------------------------------- | ----------------------------------------------------------------------------------------------------- |\n| `config.get()`       | Get config info                   | <a href={typesUrl}><code>Config</code></a>                                                            |\n| `config.providers()` | List providers and default models | `{ providers: `<a href={typesUrl}><code>Provider[]</code></a>`, default: { [key: string]: string } }` |\n\n---\n\n#### Examples\n\n```javascript\nconst config = await client.config.get()\n\nconst { providers, default: defaults } = await client.config.providers()\n```\n\n---\n\n### Sessions\n\n| Method                                                     | Description                        | Notes                                                                                                                          |\n| ---------------------------------------------------------- | ---------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n| `session.list()`                                           | List sessions                      | Returns <a href={typesUrl}><code>Session[]</code></a>                                                                          |\n| `session.get({ path })`                                    | Get session                        | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.children({ path })`                               | List child sessions                | Returns <a href={typesUrl}><code>Session[]</code></a>                                                                          |\n| `session.create({ body })`                                 | Create session                     | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.delete({ path })`                                 | Delete session                     | Returns `boolean`                                                                                                              |\n| `session.update({ path, body })`                           | Update session properties          | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.init({ path, body })`                             | Analyze app and create `AGENTS.md` | Returns `boolean`                                                                                                              |\n| `session.abort({ path })`                                  | Abort a running session            | Returns `boolean`                                                                                                              |\n| `session.share({ path })`                                  | Share session                      | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.unshare({ path })`                                | Unshare session                    | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.summarize({ path, body })`                        | Summarize session                  | Returns `boolean`                                                                                                              |\n| `session.messages({ path })`                               | List messages in a session         | Returns `{ info: `<a href={typesUrl}><code>Message</code></a>`, parts: `<a href={typesUrl}><code>Part[]</code></a>`}[]`        |\n| `session.message({ path })`                                | Get message details                | Returns `{ info: `<a href={typesUrl}><code>Message</code></a>`, parts: `<a href={typesUrl}><code>Part[]</code></a>`}`          |\n| `session.prompt({ path, body })`                           | Send prompt message                | Returns `{ info: `<a href={typesUrl}><code>AssistantMessage</code></a>`, parts: `<a href={typesUrl}><code>Part[]</code></a>`}` |\n| `session.command({ path, body })`                          | Send command to session            | Returns `{ info: `<a href={typesUrl}><code>AssistantMessage</code></a>`, parts: `<a href={typesUrl}><code>Part[]</code></a>`}` |\n| `session.shell({ path, body })`                            | Run a shell command                | Returns <a href={typesUrl}><code>AssistantMessage</code></a>                                                                   |\n| `session.revert({ path, body })`                           | Revert a message                   | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `session.unrevert({ path })`                               | Restore reverted messages          | Returns <a href={typesUrl}><code>Session</code></a>                                                                            |\n| `postSessionByIdPermissionsByPermissionId({ path, body })` | Respond to a permission request    | Returns `boolean`                                                                                                              |\n\n---\n\n#### Examples\n\n```javascript\n// Create and manage sessions\nconst session = await client.session.create({\n  body: { title: \"My session\" },\n})\n\nconst sessions = await client.session.list()\n\n// Send a prompt message\nconst result = await client.session.prompt({\n  path: { id: session.id },\n  body: {\n    model: { providerID: \"anthropic\", modelID: \"claude-3-5-sonnet-20241022\" },\n    parts: [{ type: \"text\", text: \"Hello!\" }],\n  },\n})\n```\n\n---\n\n### Files\n\n| Method                    | Description                  | Response                                                                                    |\n| ------------------------- | ---------------------------- | ------------------------------------------------------------------------------------------- |\n| `find.text({ query })`    | Search for text in files     | Array of match objects with `path`, `lines`, `line_number`, `absolute_offset`, `submatches` |\n| `find.files({ query })`   | Find files by name           | `string[]` (file paths)                                                                     |\n| `find.symbols({ query })` | Find workspace symbols       | <a href={typesUrl}><code>Symbol[]</code></a>                                                |\n| `file.read({ query })`    | Read a file                  | `{ type: \"raw\" \\| \"patch\", content: string }`                                               |\n| `file.status({ query? })` | Get status for tracked files | <a href={typesUrl}><code>File[]</code></a>                                                  |\n\n---\n\n#### Examples\n\n```javascript\n// Search and read files\nconst textResults = await client.find.text({\n  query: { pattern: \"function.*opencode\" },\n})\n\nconst files = await client.find.files({\n  query: { query: \"*.ts\" },\n})\n\nconst content = await client.file.read({\n  query: { path: \"src/index.ts\" },\n})\n```\n\n---\n\n### TUI\n\n| Method                         | Description               | Response  |\n| ------------------------------ | ------------------------- | --------- |\n| `tui.appendPrompt({ body })`   | Append text to the prompt | `boolean` |\n| `tui.openHelp()`               | Open the help dialog      | `boolean` |\n| `tui.openSessions()`           | Open the session selector | `boolean` |\n| `tui.openThemes()`             | Open the theme selector   | `boolean` |\n| `tui.openModels()`             | Open the model selector   | `boolean` |\n| `tui.submitPrompt()`           | Submit the current prompt | `boolean` |\n| `tui.clearPrompt()`            | Clear the prompt          | `boolean` |\n| `tui.executeCommand({ body })` | Execute a command         | `boolean` |\n| `tui.showToast({ body })`      | Show toast notification   | `boolean` |\n\n---\n\n#### Examples\n\n```javascript\n// Control TUI interface\nawait client.tui.appendPrompt({\n  body: { text: \"Add this to prompt\" },\n})\n\nawait client.tui.showToast({\n  body: { message: \"Task completed\", variant: \"success\" },\n})\n```\n\n---\n\n### Auth\n\n| Method              | Description                    | Response  |\n| ------------------- | ------------------------------ | --------- |\n| `auth.set({ ... })` | Set authentication credentials | `boolean` |\n\n---\n\n#### Examples\n\n```javascript\nawait client.auth.set({\n  path: { id: \"anthropic\" },\n  body: { type: \"api\", key: \"your-api-key\" },\n})\n```\n\n---\n\n### Events\n\n| Method              | Description               | Response                  |\n| ------------------- | ------------------------- | ------------------------- |\n| `event.subscribe()` | Server-sent events stream | Server-sent events stream |\n\n---\n\n#### Examples\n\n```javascript\n// Listen to real-time events\nconst events = await client.event.subscribe()\nfor await (const event of events.stream) {\n  console.log(\"Event:\", event.type, event.properties)\n}\n```","src/content/docs/sdk.mdx","6748fcf4ff2d617a","share",{id:245,data:247,body:253,filePath:254,digest:255,deferredRender:16},{title:248,description:249,editUrl:16,head:250,template:18,sidebar:251,pagefind:16,draft:20},"Share","Share your OpenCode conversations.",[],{hidden:20,attrs:252},{},"OpenCode's share feature allows you to create public links to your OpenCode conversations, so you can collaborate with teammates or get help from others.\n\n:::note\nShared conversations are publicly accessible to anyone with the link.\n:::\n\n---\n\n## How it works\n\nWhen you share a conversation, OpenCode:\n\n1. Creates a unique public URL for your session\n2. Syncs your conversation history to our servers\n3. Makes the conversation accessible via the shareable link — `opencode.ai/s/<share-id>`\n\n---\n\n## Sharing\n\nOpenCode supports three sharing modes that control how conversations are shared:\n\n---\n\n### Manual (default)\n\nBy default, OpenCode uses manual sharing mode. Sessions are not shared automatically, but you can manually share them using the `/share` command:\n\n```\n/share\n```\n\nThis will generate a unique URL that'll be copied to your clipboard.\n\nTo explicitly set manual mode in your [config file](/docs/config):\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"share\": \"manual\"\n}\n```\n\n---\n\n### Auto-share\n\nYou can enable automatic sharing for all new conversations by setting the `share` option to `\"auto\"` in your [config file](/docs/config):\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"share\": \"auto\"\n}\n```\n\nWith auto-share enabled, every new conversation will automatically be shared and a link will be generated.\n\n---\n\n### Disabled\n\nYou can disable sharing entirely by setting the `share` option to `\"disabled\"` in your [config file](/docs/config):\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"share\": \"disabled\"\n}\n```\n\nTo enforce this across your team for a given project, add it to the `opencode.json` in your project and check into Git.\n\n---\n\n## Un-sharing\n\nTo stop sharing a conversation and remove it from public access:\n\n```\n/unshare\n```\n\nThis will remove the share link and delete the data related to the conversation.\n\n---\n\n## Privacy\n\nThere are a few things to keep in mind when sharing a conversation.\n\n---\n\n### Data retention\n\nShared conversations remain accessible until you explicitly unshare them. This\nincludes:\n\n- Full conversation history\n- All messages and responses\n- Session metadata\n\n---\n\n### Recommendations\n\n- Only share conversations that don't contain sensitive information.\n- Review conversation content before sharing.\n- Unshare conversations when collaboration is complete.\n- Avoid sharing conversations with proprietary code or confidential data.\n- For sensitive projects, disable sharing entirely.\n\n---\n\n## For enterprises\n\nFor enterprise deployments, the share feature can be:\n\n- **Disabled** entirely for security compliance\n- **Restricted** to users authenticated through SSO only\n- **Self-hosted** on your own infrastructure\n\n[Learn more](/docs/enterprise) about using opencode in your organization.","src/content/docs/share.mdx","2aefe1741f0dccd9","server",{id:256,data:258,body:264,filePath:265,digest:266,deferredRender:16},{title:259,description:260,editUrl:16,head:261,template:18,sidebar:262,pagefind:16,draft:20},"Server","Interact with opencode server over HTTP.",[],{hidden:20,attrs:263},{},"import config from \"../../../config.mjs\"\nexport const typesUrl = `${config.github}/blob/dev/packages/sdk/js/src/gen/types.gen.ts`\n\nThe `opencode serve` command runs a headless HTTP server that exposes an OpenAPI endpoint that an opencode client can use.\n\n---\n\n### Usage\n\n```bash\nopencode serve [--port <number>] [--hostname <string>]\n```\n\n#### Options\n\n| Flag         | Short | Description           | Default     |\n| ------------ | ----- | --------------------- | ----------- |\n| `--port`     | `-p`  | Port to listen on     | `4096`      |\n| `--hostname` | `-h`  | Hostname to listen on | `127.0.0.1` |\n\n---\n\n### How it works\n\nWhen you run `opencode` it starts a TUI and a server. Where the TUI is the\nclient that talks to the server. The server exposes an OpenAPI 3.1 spec\nendpoint. This endpoint is also used to generate an [SDK](/docs/sdk).\n\n:::tip\nUse the opencode server to interact with opencode programmatically.\n:::\n\nThis architecture lets opencode support multiple clients and allows you to interact with opencode programmatically.\n\nYou can run `opencode serve` to start a standalone server. If you have the\nopencode TUI running, `opencode serve` will start a new server.\n\n---\n\n#### Connect to an existing server\n\nWhen you start the TUI it randomly assigns a port and hostname. You can instead pass in the `--hostname` and `--port` [flags](/docs/cli). Then use this to connect to its server.\n\nThe [`/tui`](#tui) endpoint can be used to drive the TUI through the server. For example, you can prefill or run a prompt. This setup is used by the OpenCode [IDE](/docs/ide) plugins.\n\n---\n\n## Spec\n\nThe server publishes an OpenAPI 3.1 spec that can be viewed at:\n\n```\nhttp://<hostname>:<port>/doc\n```\n\nFor example, `http://localhost:4096/doc`. Use the spec to generate clients or inspect request and response types. Or view it in a Swagger explorer.\n\n---\n\n## APIs\n\nThe opencode server exposes the following APIs.\n\n---\n\n### App\n\n| Method | Path        | Description        | Response                                |\n| ------ | ----------- | ------------------ | --------------------------------------- |\n| `GET`  | `/app`      | Get app info       | <a href={typesUrl}><code>App</code></a> |\n| `POST` | `/app/init` | Initialize the app | `boolean`                               |\n\n---\n\n### Config\n\n| Method | Path                | Description                       | Response                                                                                 |\n| ------ | ------------------- | --------------------------------- | ---------------------------------------------------------------------------------------- |\n| `GET`  | `/config`           | Get config info                   | <a href={typesUrl}><code>Config</code></a>                                               |\n| `GET`  | `/config/providers` | List providers and default models | `{ providers: `<a href={typesUrl}>Provider[]</a>`, default: { [key: string]: string } }` |\n\n---\n\n### Sessions\n\n| Method   | Path                                     | Description                        | Notes                                                                                                                                                                      |\n| -------- | ---------------------------------------- | ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `GET`    | `/session`                               | List sessions                      | Returns <a href={typesUrl}><code>Session[]</code></a>                                                                                                                      |\n| `GET`    | `/session/:id`                           | Get session                        | Returns <a href={typesUrl}><code>Session</code></a>                                                                                                                        |\n| `GET`    | `/session/:id/children`                  | List child sessions                | Returns <a href={typesUrl}><code>Session[]</code></a>                                                                                                                      |\n| `POST`   | `/session`                               | Create session                     | body: `{ parentID?, title? }`, returns <a href={typesUrl}><code>Session</code></a>                                                                                         |\n| `DELETE` | `/session/:id`                           | Delete session                     |                                                                                                                                                                            |\n| `PATCH`  | `/session/:id`                           | Update session properties          | body: `{ title? }`, returns <a href={typesUrl}><code>Session</code></a>                                                                                                    |\n| `POST`   | `/session/:id/init`                      | Analyze app and create `AGENTS.md` | body: `{ messageID, providerID, modelID }`                                                                                                                                 |\n| `POST`   | `/session/:id/abort`                     | Abort a running session            |                                                                                                                                                                            |\n| `POST`   | `/session/:id/share`                     | Share session                      | Returns <a href={typesUrl}><code>Session</code></a>                                                                                                                        |\n| `DELETE` | `/session/:id/share`                     | Unshare session                    | Returns <a href={typesUrl}><code>Session</code></a>                                                                                                                        |\n| `POST`   | `/session/:id/summarize`                 | Summarize session                  |                                                                                                                                                                            |\n| `GET`    | `/session/:id/message`                   | List messages in a session         | Returns `{ info: `<a href={typesUrl}>Message</a>`, parts: `<a href={typesUrl}>Part[]</a>`}[]`                                                                              |\n| `GET`    | `/session/:id/message/:messageID`        | Get message details                | Returns `{ info: `<a href={typesUrl}>Message</a>`, parts: `<a href={typesUrl}>Part[]</a>`}`                                                                                |\n| `POST`   | `/session/:id/message`                   | Send chat message                  | body matches [`ChatInput`](https://github.com/sst/opencode/blob/main/packages/opencode/src/session/index.ts#L358), returns <a href={typesUrl}><code>Message</code></a>     |\n| `POST`   | `/session/:id/shell`                     | Run a shell command                | body matches [`CommandInput`](https://github.com/sst/opencode/blob/main/packages/opencode/src/session/index.ts#L1007), returns <a href={typesUrl}><code>Message</code></a> |\n| `POST`   | `/session/:id/revert`                    | Revert a message                   | body: `{ messageID }`                                                                                                                                                      |\n| `POST`   | `/session/:id/unrevert`                  | Restore reverted messages          |                                                                                                                                                                            |\n| `POST`   | `/session/:id/permissions/:permissionID` | Respond to a permission request    | body: `{ response }`                                                                                                                                                       |\n\n---\n\n### Files\n\n| Method | Path                     | Description                  | Response                                                                                    |\n| ------ | ------------------------ | ---------------------------- | ------------------------------------------------------------------------------------------- |\n| `GET`  | `/find?pattern=<pat>`    | Search for text in files     | Array of match objects with `path`, `lines`, `line_number`, `absolute_offset`, `submatches` |\n| `GET`  | `/find/file?query=<q>`   | Find files by name           | `string[]` (file paths)                                                                     |\n| `GET`  | `/find/symbol?query=<q>` | Find workspace symbols       | <a href={typesUrl}><code>Symbol[]</code></a>                                                |\n| `GET`  | `/file?path=<path>`      | Read a file                  | `{ type: \"raw\" \\| \"patch\", content: string }`                                               |\n| `GET`  | `/file/status`           | Get status for tracked files | <a href={typesUrl}><code>File[]</code></a>                                                  |\n\n---\n\n### Logging\n\n| Method | Path   | Description                                                  | Response  |\n| ------ | ------ | ------------------------------------------------------------ | --------- |\n| `POST` | `/log` | Write log entry. Body: `{ service, level, message, extra? }` | `boolean` |\n\n---\n\n### Agents\n\n| Method | Path     | Description               | Response                                    |\n| ------ | -------- | ------------------------- | ------------------------------------------- |\n| `GET`  | `/agent` | List all available agents | <a href={typesUrl}><code>Agent[]</code></a> |\n\n---\n\n### TUI\n\n| Method | Path                    | Description                                 | Response               |\n| ------ | ----------------------- | ------------------------------------------- | ---------------------- |\n| `POST` | `/tui/append-prompt`    | Append text to the prompt                   | `boolean`              |\n| `POST` | `/tui/open-help`        | Open the help dialog                        | `boolean`              |\n| `POST` | `/tui/open-sessions`    | Open the session selector                   | `boolean`              |\n| `POST` | `/tui/open-themes`      | Open the theme selector                     | `boolean`              |\n| `POST` | `/tui/open-models`      | Open the model selector                     | `boolean`              |\n| `POST` | `/tui/submit-prompt`    | Submit the current prompt                   | `boolean`              |\n| `POST` | `/tui/clear-prompt`     | Clear the prompt                            | `boolean`              |\n| `POST` | `/tui/execute-command`  | Execute a command (`{ command }`)           | `boolean`              |\n| `POST` | `/tui/show-toast`       | Show toast (`{ title?, message, variant }`) | `boolean`              |\n| `GET`  | `/tui/control/next`     | Wait for the next control request           | Control request object |\n| `POST` | `/tui/control/response` | Respond to a control request (`{ body }`)   | `boolean`              |\n\n---\n\n### Auth\n\n| Method | Path        | Description                                                     | Response  |\n| ------ | ----------- | --------------------------------------------------------------- | --------- |\n| `PUT`  | `/auth/:id` | Set authentication credentials. Body must match provider schema | `boolean` |\n\n---\n\n### Events\n\n| Method | Path     | Description                                                                   | Response                  |\n| ------ | -------- | ----------------------------------------------------------------------------- | ------------------------- |\n| `GET`  | `/event` | Server-sent events stream. First event is `server.connected`, then bus events | Server-sent events stream |\n\n---\n\n### Docs\n\n| Method | Path   | Description               | Response                    |\n| ------ | ------ | ------------------------- | --------------------------- |\n| `GET`  | `/doc` | OpenAPI 3.1 specification | HTML page with OpenAPI spec |","src/content/docs/server.mdx","e08cd2c3d18c354d","themes",{id:267,data:269,body:275,filePath:276,digest:277,deferredRender:16},{title:270,description:271,editUrl:16,head:272,template:18,sidebar:273,pagefind:16,draft:20},"Themes","Select a built-in theme or define your own.",[],{hidden:20,attrs:274},{},"With OpenCode you can select from one of several built-in themes, use a theme that adapts to your terminal theme, or define your own custom theme.\n\nBy default, OpenCode uses our own `opencode` theme.\n\n---\n\n## Terminal requirements\n\nFor themes to display correctly with their full color palette, your terminal must support **truecolor** (24-bit color). Most modern terminals support this by default, but you may need to enable it:\n\n- **Check support**: Run `echo $COLORTERM` - it should output `truecolor` or `24bit`\n- **Enable truecolor**: Set the environment variable `COLORTERM=truecolor` in your shell profile\n- **Terminal compatibility**: Ensure your terminal emulator supports 24-bit color (most modern terminals like iTerm2, Alacritty, Kitty, Windows Terminal, and recent versions of GNOME Terminal do)\n\nWithout truecolor support, themes may appear with reduced color accuracy or fall back to the nearest 256-color approximation.\n\n---\n\n## Built-in themes\n\nOpenCode comes with several built-in themes.\n\n| Name         | Description                                                                  |\n| ------------ | ---------------------------------------------------------------------------- |\n| `system`     | Adapts to your terminal's background color                                   |\n| `tokyonight` | Based on the [Tokyonight](https://github.com/folke/tokyonight.nvim) theme    |\n| `everforest` | Based on the [Everforest](https://github.com/sainnhe/everforest) theme       |\n| `ayu`        | Based on the [Ayu](https://github.com/ayu-theme) dark theme                  |\n| `catppuccin` | Based on the [Catppuccin](https://github.com/catppuccin) theme               |\n| `gruvbox`    | Based on the [Gruvbox](https://github.com/morhetz/gruvbox) theme             |\n| `kanagawa`   | Based on the [Kanagawa](https://github.com/rebelot/kanagawa.nvim) theme      |\n| `nord`       | Based on the [Nord](https://github.com/nordtheme/nord) theme                 |\n| `matrix`     | Hacker-style green on black theme                                            |\n| `one-dark`   | Based on the [Atom One](https://github.com/Th3Whit3Wolf/one-nvim) Dark theme |\n\nAnd more, we are constantly adding new themes.\n\n---\n\n## System theme\n\nThe `system` theme is designed to automatically adapt to your terminal's color scheme. Unlike traditional themes that use fixed colors, the _system_ theme:\n\n- **Generates gray scale**: Creates a custom gray scale based on your terminal's background color, ensuring optimal contrast.\n- **Uses ANSI colors**: Leverages standard ANSI colors (0-15) for syntax highlighting and UI elements, which respect your terminal's color palette.\n- **Preserves terminal defaults**: Uses `none` for text and background colors to maintain your terminal's native appearance.\n\nThe system theme is for users who:\n\n- Want OpenCode to match their terminal's appearance\n- Use custom terminal color schemes\n- Prefer a consistent look across all terminal applications\n\n---\n\n## Using a theme\n\nYou can select a theme by bringing up the theme select with the `/theme` command. Or you can specify it in your [config](/docs/config).\n\n```json title=\"opencode.json\" {3}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"theme\": \"tokyonight\"\n}\n```\n\n---\n\n## Custom themes\n\nOpenCode supports a flexible JSON-based theme system that allows users to create and customize themes easily.\n\n---\n\n### Hierarchy\n\nThemes are loaded from multiple directories in the following order where later directories override earlier ones:\n\n1. **Built-in themes** - These are embedded in the binary\n2. **User config directory** - Defined in `~/.config/opencode/themes/*.json` or `$XDG_CONFIG_HOME/opencode/themes/*.json`\n3. **Project root directory** - Defined in the `<project-root>/.opencode/themes/*.json`\n4. **Current working directory** - Defined in `./.opencode/themes/*.json`\n\nIf multiple directories contain a theme with the same name, the theme from the directory with higher priority will be used.\n\n---\n\n### Creating a theme\n\nTo create a custom theme, create a JSON file in one of the theme directories.\n\nFor user-wide themes:\n\n```bash no-frame\nmkdir -p ~/.config/opencode/themes\nvim ~/.config/opencode/themes/my-theme.json\n```\n\nAnd for project-specific themes.\n\n```bash no-frame\nmkdir -p .opencode/themes\nvim .opencode/themes/my-theme.json\n```\n\n---\n\n### JSON format\n\nThemes use a flexible JSON format with support for:\n\n- **Hex colors**: `\"#ffffff\"`\n- **ANSI colors**: `3` (0-255)\n- **Color references**: `\"primary\"` or custom definitions\n- **Dark/light variants**: `{\"dark\": \"#000\", \"light\": \"#fff\"}`\n- **No color**: `\"none\"` - Uses the terminal's default color or transparent\n\n---\n\n### Color definitions\n\nThe `defs` section is optional and it allows you to define reusable colors that can be referenced in the theme.\n\n---\n\n### Terminal defaults\n\nThe special value `\"none\"` can be used for any color to inherit the terminal's default color. This is particularly useful for creating themes that blend seamlessly with your terminal's color scheme:\n\n- `\"text\": \"none\"` - Uses terminal's default foreground color\n- `\"background\": \"none\"` - Uses terminal's default background color\n\n---\n\n### Example\n\nHere's an example of a custom theme:\n\n```json title=\"my-theme.json\"\n{\n  \"$schema\": \"https://opencode.ai/theme.json\",\n  \"defs\": {\n    \"nord0\": \"#2E3440\",\n    \"nord1\": \"#3B4252\",\n    \"nord2\": \"#434C5E\",\n    \"nord3\": \"#4C566A\",\n    \"nord4\": \"#D8DEE9\",\n    \"nord5\": \"#E5E9F0\",\n    \"nord6\": \"#ECEFF4\",\n    \"nord7\": \"#8FBCBB\",\n    \"nord8\": \"#88C0D0\",\n    \"nord9\": \"#81A1C1\",\n    \"nord10\": \"#5E81AC\",\n    \"nord11\": \"#BF616A\",\n    \"nord12\": \"#D08770\",\n    \"nord13\": \"#EBCB8B\",\n    \"nord14\": \"#A3BE8C\",\n    \"nord15\": \"#B48EAD\"\n  },\n  \"theme\": {\n    \"primary\": {\n      \"dark\": \"nord8\",\n      \"light\": \"nord10\"\n    },\n    \"secondary\": {\n      \"dark\": \"nord9\",\n      \"light\": \"nord9\"\n    },\n    \"accent\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"error\": {\n      \"dark\": \"nord11\",\n      \"light\": \"nord11\"\n    },\n    \"warning\": {\n      \"dark\": \"nord12\",\n      \"light\": \"nord12\"\n    },\n    \"success\": {\n      \"dark\": \"nord14\",\n      \"light\": \"nord14\"\n    },\n    \"info\": {\n      \"dark\": \"nord8\",\n      \"light\": \"nord10\"\n    },\n    \"text\": {\n      \"dark\": \"nord4\",\n      \"light\": \"nord0\"\n    },\n    \"textMuted\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord1\"\n    },\n    \"background\": {\n      \"dark\": \"nord0\",\n      \"light\": \"nord6\"\n    },\n    \"backgroundPanel\": {\n      \"dark\": \"nord1\",\n      \"light\": \"nord5\"\n    },\n    \"backgroundElement\": {\n      \"dark\": \"nord1\",\n      \"light\": \"nord4\"\n    },\n    \"border\": {\n      \"dark\": \"nord2\",\n      \"light\": \"nord3\"\n    },\n    \"borderActive\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord2\"\n    },\n    \"borderSubtle\": {\n      \"dark\": \"nord2\",\n      \"light\": \"nord3\"\n    },\n    \"diffAdded\": {\n      \"dark\": \"nord14\",\n      \"light\": \"nord14\"\n    },\n    \"diffRemoved\": {\n      \"dark\": \"nord11\",\n      \"light\": \"nord11\"\n    },\n    \"diffContext\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord3\"\n    },\n    \"diffHunkHeader\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord3\"\n    },\n    \"diffHighlightAdded\": {\n      \"dark\": \"nord14\",\n      \"light\": \"nord14\"\n    },\n    \"diffHighlightRemoved\": {\n      \"dark\": \"nord11\",\n      \"light\": \"nord11\"\n    },\n    \"diffAddedBg\": {\n      \"dark\": \"#3B4252\",\n      \"light\": \"#E5E9F0\"\n    },\n    \"diffRemovedBg\": {\n      \"dark\": \"#3B4252\",\n      \"light\": \"#E5E9F0\"\n    },\n    \"diffContextBg\": {\n      \"dark\": \"nord1\",\n      \"light\": \"nord5\"\n    },\n    \"diffLineNumber\": {\n      \"dark\": \"nord2\",\n      \"light\": \"nord4\"\n    },\n    \"diffAddedLineNumberBg\": {\n      \"dark\": \"#3B4252\",\n      \"light\": \"#E5E9F0\"\n    },\n    \"diffRemovedLineNumberBg\": {\n      \"dark\": \"#3B4252\",\n      \"light\": \"#E5E9F0\"\n    },\n    \"markdownText\": {\n      \"dark\": \"nord4\",\n      \"light\": \"nord0\"\n    },\n    \"markdownHeading\": {\n      \"dark\": \"nord8\",\n      \"light\": \"nord10\"\n    },\n    \"markdownLink\": {\n      \"dark\": \"nord9\",\n      \"light\": \"nord9\"\n    },\n    \"markdownLinkText\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"markdownCode\": {\n      \"dark\": \"nord14\",\n      \"light\": \"nord14\"\n    },\n    \"markdownBlockQuote\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord3\"\n    },\n    \"markdownEmph\": {\n      \"dark\": \"nord12\",\n      \"light\": \"nord12\"\n    },\n    \"markdownStrong\": {\n      \"dark\": \"nord13\",\n      \"light\": \"nord13\"\n    },\n    \"markdownHorizontalRule\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord3\"\n    },\n    \"markdownListItem\": {\n      \"dark\": \"nord8\",\n      \"light\": \"nord10\"\n    },\n    \"markdownListEnumeration\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"markdownImage\": {\n      \"dark\": \"nord9\",\n      \"light\": \"nord9\"\n    },\n    \"markdownImageText\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"markdownCodeBlock\": {\n      \"dark\": \"nord4\",\n      \"light\": \"nord0\"\n    },\n    \"syntaxComment\": {\n      \"dark\": \"nord3\",\n      \"light\": \"nord3\"\n    },\n    \"syntaxKeyword\": {\n      \"dark\": \"nord9\",\n      \"light\": \"nord9\"\n    },\n    \"syntaxFunction\": {\n      \"dark\": \"nord8\",\n      \"light\": \"nord8\"\n    },\n    \"syntaxVariable\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"syntaxString\": {\n      \"dark\": \"nord14\",\n      \"light\": \"nord14\"\n    },\n    \"syntaxNumber\": {\n      \"dark\": \"nord15\",\n      \"light\": \"nord15\"\n    },\n    \"syntaxType\": {\n      \"dark\": \"nord7\",\n      \"light\": \"nord7\"\n    },\n    \"syntaxOperator\": {\n      \"dark\": \"nord9\",\n      \"light\": \"nord9\"\n    },\n    \"syntaxPunctuation\": {\n      \"dark\": \"nord4\",\n      \"light\": \"nord0\"\n    }\n  }\n}\n```","src/content/docs/themes.mdx","83f9a7082a46bb57","tools",{id:278,data:280,body:286,filePath:287,digest:288,deferredRender:16},{title:281,description:282,editUrl:16,head:283,template:18,sidebar:284,pagefind:16,draft:20},"Tools","Manage the tools an LLM can use.",[],{hidden:20,attrs:285},{},"Tools allow the LLM to perform actions in your codebase. OpenCode comes with a set of built-in tools, but you can extend it with [custom tools](/docs/custom-tools) or [MCP servers](/docs/mcp-servers).\n\nBy default, all tools are **enabled** and don't need permission to run. But you can configure this and control the [permissions](/docs/permissions) through your config.\n\n---\n\n## Configure\n\nYou can configure tools globally or per agent. Agent-specific configs override global settings.\n\nBy default, all tools are set to `true`. To disable a tool, set it to `false`.\n\n---\n\n### Global\n\nDisable or enable tools globally using the `tools` option.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"write\": false,\n    \"bash\": false,\n    \"webfetch\": true\n  }\n}\n```\n\nYou can also use wildcards to control multiple tools at once. For example, to disable all tools from an MCP server:\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"mymcp_*\": false\n  }\n}\n```\n\n---\n\n### Per agent\n\nOverride global tool settings for specific agents using the `tools` config in the agent definition.\n\n```json title=\"opencode.json\" {3-6,9-12}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"write\": true,\n    \"bash\": true\n  },\n  \"agent\": {\n    \"plan\": {\n      \"tools\": {\n        \"write\": false,\n        \"bash\": false\n      }\n    }\n  }\n}\n```\n\nFor example, here the `plan` agent overrides the global config to disable `write` and `bash` tools.\n\nYou can also configure tools for agents in Markdown.\n\n```markdown title=\"~/.config/opencode/agent/readonly.md\"\n---\ndescription: Read-only analysis agent\nmode: subagent\ntools:\n  write: false\n  edit: false\n  bash: false\n---\n\nAnalyze code without making any modifications.\n```\n\n[Learn more](/docs/agents#tools) about configuring tools per agent.\n\n---\n\n## Built-in\n\nHere are all the built-in tools available in OpenCode.\n\n---\n\n### bash\n\nExecute shell commands in your project environment.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"bash\": true\n  }\n}\n```\n\nThis tool allows the LLM to run terminal commands like `npm install`, `git status`, or any other shell command.\n\n---\n\n### edit\n\nModify existing files using exact string replacements.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"edit\": true\n  }\n}\n```\n\nThis tool performs precise edits to files by replacing exact text matches. It's the primary way the LLM modifies code.\n\n---\n\n### write\n\nCreate new files or overwrite existing ones.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"write\": true\n  }\n}\n```\n\nUse this to allow the LLM to create new files. It will overwrite existing files if they already exist.\n\n---\n\n### read\n\nRead file contents from your codebase.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"read\": true\n  }\n}\n```\n\nThis tool reads files and returns their contents. It supports reading specific line ranges for large files.\n\n---\n\n### grep\n\nSearch file contents using regular expressions.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"grep\": true\n  }\n}\n```\n\nFast content search across your codebase. Supports full regex syntax and file pattern filtering.\n\n---\n\n### glob\n\nFind files by pattern matching.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"glob\": true\n  }\n}\n```\n\nSearch for files using glob patterns like `**/*.js` or `src/**/*.ts`. Returns matching file paths sorted by modification time.\n\n---\n\n### list\n\nList files and directories in a given path.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"list\": true\n  }\n}\n```\n\nThis tool lists directory contents. It accepts glob patterns to filter results.\n\n---\n\n### patch\n\nApply patches to files.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"patch\": true\n  }\n}\n```\n\nThis tool applies patch files to your codebase. Useful for applying diffs and patches from various sources.\n\n---\n\n### todowrite\n\nManage todo lists during coding sessions.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"todowrite\": true\n  }\n}\n```\n\nCreates and updates task lists to track progress during complex operations. The LLM uses this to organize multi-step tasks.\n\n---\n\n### todoread\n\nRead existing todo lists.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"todoread\": true\n  }\n}\n```\n\nReads the current todo list state. Used by the LLM to track what tasks are pending or completed.\n\n---\n\n### webfetch\n\nFetch web content.\n\n```json title=\"opencode.json\" {4}\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tools\": {\n    \"webfetch\": true\n  }\n}\n```\n\nAllows the LLM to fetch and read web pages. Useful for looking up documentation or researching online resources.\n\n---\n\n## Custom tools\n\nCustom tools let you define your own functions that the LLM can call. These are defined in your config file and can execute arbitrary code.\n\n[Learn more](/docs/custom-tools) about creating custom tools.\n\n---\n\n## MCP servers\n\nMCP (Model Context Protocol) servers allow you to integrate external tools and services. This includes database access, API integrations, and third-party services.\n\n[Learn more](/docs/mcp-servers) about configuring MCP servers.\n\n---\n\n## Internals\n\nInternally, tools like `grep`, `glob`, and `list` use [ripgrep](https://github.com/BurntSushi/ripgrep) under the hood. By default, ripgrep respects `.gitignore` patterns, which means files and directories listed in your `.gitignore` will be excluded from searches and listings.\n\n---\n\n### Ignore patterns\n\nTo include files that would normally be ignored, create a `.ignore` file in your project root. This file can explicitly allow certain paths.\n\n```text title=\".ignore\"\n!node_modules/\n!dist/\n!build/\n```\n\nFor example, this `.ignore` file allows ripgrep to search within `node_modules/`, `dist/`, and `build/` directories even if they're listed in `.gitignore`.","src/content/docs/tools.mdx","9c662557f1cacd93","troubleshooting",{id:289,data:291,body:297,filePath:298,digest:299,deferredRender:16},{title:292,description:293,editUrl:16,head:294,template:18,sidebar:295,pagefind:16,draft:20},"Troubleshooting","Common issues and how to resolve them.",[],{hidden:20,attrs:296},{},"To debug any issues with OpenCode, you can check the logs or the session data\nthat it stores locally.\n\n---\n\n### Logs\n\nLog files are written to:\n\n- **macOS/Linux**: `~/.local/share/opencode/log/`\n- **Windows**: `%USERPROFILE%\\.local\\share\\opencode\\log\\`\n\nLog files are named with timestamps (e.g., `2025-01-09T123456.log`) and the most recent 10 log files are kept.\n\nYou can set the log level with the `--log-level` command-line option to get more detailed debug information. For example, `opencode --log-level DEBUG`.\n\n---\n\n### Storage\n\nopencode stores session data and other application data on disk at:\n\n- **macOS/Linux**: `~/.local/share/opencode/`\n- **Windows**: `%USERPROFILE%\\.local\\share\\opencode`\n\nThis directory contains:\n\n- `auth.json` - Authentication data like API keys, OAuth tokens\n- `log/` - Application logs\n- `project/` - Project-specific data like session and message data\n  - If the project is within a Git repo, it is stored in `./<project-slug>/storage/`\n  - If it is not a Git repo, it is stored in `./global/storage/`\n\n---\n\n## Getting help\n\nIf you're experiencing issues with OpenCode:\n\n1. **Report issues on GitHub**\n\n   The best way to report bugs or request features is through our GitHub repository:\n\n   [**github.com/sst/opencode/issues**](https://github.com/sst/opencode/issues)\n\n   Before creating a new issue, search existing issues to see if your problem has already been reported.\n\n2. **Join our Discord**\n\n   For real-time help and community discussion, join our Discord server:\n\n   [**opencode.ai/discord**](https://opencode.ai/discord)\n\n---\n\n## Common issues\n\nHere are some common issues and how to resolve them.\n\n---\n\n### opencode won't start\n\n1. Check the logs for error messages\n2. Try running with `--print-logs` to see output in the terminal\n3. Ensure you have the latest version with `opencode upgrade`\n\n---\n\n### Authentication issues\n\n1. Try re-authenticating with `opencode auth login <provider>`\n2. Check that your API keys are valid\n3. Ensure your network allows connections to the provider's API\n\n---\n\n### Model not available\n\n1. Check that you've authenticated with the provider\n2. Verify the model name in your config is correct\n3. Some models may require specific access or subscriptions\n\nIf you encounter `ProviderModelNotFoundError` you are most likely incorrectly\nreferencing a model somewhere.\nModels should be referenced like so: `<providerId>/<modelId>`\n\n\nExamples:\n- `openai/gpt-4.1`\n- `openrouter/google/gemini-2.5-flash`\n- `opencode/kimi-k2`\n\nTo figure out what models you have access to, run `opencode models`\n\n---\n\n### ProviderInitError\n\nIf you encounter a ProviderInitError, you likely have an invalid or corrupted configuration.\n\nTo resolve this:\n\n1. First, verify your provider is set up correctly by following the [providers guide](/docs/providers)\n2. If the issue persists, try clearing your stored configuration:\n\n   ```bash\n   rm -rf ~/.local/share/opencode\n   ```\n\n3. Re-authenticate with your provider:\n   ```bash\n   opencode auth login <provider>\n   ```\n\n---\n\n### AI_APICallError and provider package issues\n\nIf you encounter API call errors, this may be due to outdated provider packages. opencode dynamically installs provider packages (OpenAI, Anthropic, Google, etc.) as needed and caches them locally.\n\nTo resolve provider package issues:\n\n1. Clear the provider package cache:\n\n   ```bash\n   rm -rf ~/.cache/opencode\n   ```\n\n2. Restart opencode to reinstall the latest provider packages\n\nThis will force opencode to download the most recent versions of provider packages, which often resolves compatibility issues with model parameters and API changes.\n\n---\n\n### Copy/paste not working on Linux\n\nLinux users need to have one of the following clipboard utilities installed for copy/paste functionality to work:\n\n**For X11 systems:**\n\n```bash\napt install -y xclip\n# or\napt install -y xsel\n```\n\n**For Wayland systems:**\n\n```bash\napt install -y wl-clipboard\n```\n\n**For headless environments:**\n\n```bash\napt install -y xvfb\n# and run:\nXvfb :99 -screen 0 1024x768x24 > /dev/null 2>&1 &\nexport DISPLAY=:99.0\n```\n\nopencode will detect if you're using Wayland and prefer `wl-clipboard`, otherwise it will try to find clipboard tools in order of: `xclip` and `xsel`.","src/content/docs/troubleshooting.mdx","a74ef0ec5fb7c0e1","tui",{id:300,data:302,body:308,filePath:309,digest:310,deferredRender:16},{title:303,description:304,editUrl:16,head:305,template:18,sidebar:306,pagefind:16,draft:20},"TUI","Using the OpenCode terminal user interface.",[],{hidden:20,attrs:307},{},"import { Tabs, TabItem } from \"@astrojs/starlight/components\"\n\nOpenCode provides an interactive terminal interface or TUI for working on your projects with an LLM.\n\nRunning OpenCode starts the TUI for the current directory.\n\n```bash\nopencode\n```\n\nOr you can start it for a specific working directory.\n\n```bash\nopencode /path/to/project\n```\n\nOnce you're in the TUI, you can prompt it with a message.\n\n```text\nGive me a quick summary of the codebase.\n```\n\n---\n\n## File references\n\nYou can reference files in your messages using `@`. This does a fuzzy file search in the current working directory.\n\n:::tip\nYou can also use `@` to reference files in your messages.\n:::\n\n```text \"@packages/functions/src/api/index.ts\"\nHow is auth handled in @packages/functions/src/api/index.ts?\n```\n\nThe content of the file is added to the conversation automatically.\n\n---\n\n## Bash commands\n\nStart a message with `!` to run a shell command.\n\n```bash frame=\"none\"\n!ls -la\n```\n\nThe output of the command is added to the conversation as a tool result.\n\n---\n\n## Commands\n\nWhen using the OpenCode TUI, you can type `/` followed by a command name to quickly execute actions. For example:\n\n```bash frame=\"none\"\n/help\n```\n\nMost commands also have keybind using `ctrl+x` as the leader key, where `ctrl+x` is the default leader key. [Learn more](/docs/keybinds).\n\nHere are all available slash commands:\n\n---\n\n### compact\n\nCompact the current session. _Alias_: `/summarize`\n\n```bash frame=\"none\"\n/compact\n```\n\n**Keybind:** `ctrl+x c`\n\n---\n\n### details\n\nToggle tool execution details.\n\n```bash frame=\"none\"\n/details\n```\n\n**Keybind:** `ctrl+x d`\n\n---\n\n### editor\n\nOpen external editor for composing messages. Uses the editor set in your `EDITOR` environment variable. [Learn more](#editor-setup).\n\n```bash frame=\"none\"\n/editor\n```\n\n**Keybind:** `ctrl+x e`\n\n---\n\n### exit\n\nExit OpenCode. _Aliases_: `/quit`, `/q`\n\n```bash frame=\"none\"\n/exit\n```\n\n**Keybind:** `ctrl+x q`\n\n---\n\n### export\n\nExport current conversation to Markdown and open in your default editor. Uses the editor set in your `EDITOR` environment variable. [Learn more](#editor-setup).\n\n```bash frame=\"none\"\n/export\n```\n\n**Keybind:** `ctrl+x x`\n\n---\n\n### help\n\nShow the help dialog.\n\n```bash frame=\"none\"\n/help\n```\n\n**Keybind:** `ctrl+x h`\n\n---\n\n### init\n\nCreate or update `AGENTS.md` file. [Learn more](/docs/rules).\n\n```bash frame=\"none\"\n/init\n```\n\n**Keybind:** `ctrl+x i`\n\n---\n\n### models\n\nList available models.\n\n```bash frame=\"none\"\n/models\n```\n\n**Keybind:** `ctrl+x m`\n\n---\n\n### new\n\nStart a new session. _Alias_: `/clear`\n\n```bash frame=\"none\"\n/new\n```\n\n**Keybind:** `ctrl+x n`\n\n---\n\n### redo\n\nRedo a previously undone message. Only available after using `/undo`.\n\n:::tip\nAny file changes will also be restored.\n:::\n\nInternally, this uses Git to manage the file changes. So your project **needs to\nbe a Git repository**.\n\n```bash frame=\"none\"\n/redo\n```\n\n**Keybind:** `ctrl+x r`\n\n---\n\n### sessions\n\nList and switch between sessions. _Aliases_: `/resume`, `/continue`\n\n```bash frame=\"none\"\n/sessions\n```\n\n**Keybind:** `ctrl+x l`\n\n---\n\n### share\n\nShare current session. [Learn more](/docs/share).\n\n```bash frame=\"none\"\n/share\n```\n\n**Keybind:** `ctrl+x s`\n\n---\n\n### themes\n\nList available themes.\n\n```bash frame=\"none\"\n/themes\n```\n\n**Keybind:** `ctrl+x t`\n\n---\n\n### undo\n\nUndo last message in the conversation. Removes the most recent user message, all subsequent responses, and any file changes.\n\n:::tip\nAny file changes made will also be reverted.\n:::\n\nInternally, this uses Git to manage the file changes. So your project **needs to\nbe a Git repository**.\n\n```bash frame=\"none\"\n/undo\n```\n\n**Keybind:** `ctrl+x u`\n\n---\n\n### unshare\n\nUnshare current session. [Learn more](/docs/share#un-sharing).\n\n```bash frame=\"none\"\n/unshare\n```\n\n---\n\n## Editor setup\n\nBoth the `/editor` and `/export` commands use the editor specified in your `EDITOR` environment variable.\n\n<Tabs>\n  <TabItem label=\"Linux/macOS\">\n    ```bash\n    # Example for nano or vim\n    export EDITOR=nano\n    export EDITOR=vim\n\n    # For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.\n    # include --wait\n    export EDITOR=\"code --wait\"\n    ```\n\n    To make it permanent, add this to your shell profile;\n    `~/.bashrc`, `~/.zshrc`, etc.\n\n  </TabItem>\n\n  <TabItem label=\"Windows (CMD)\">\n    ```bash\n    set EDITOR=notepad\n\n    # For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.\n    # include --wait\n    set EDITOR=code --wait\n    ```\n\n    To make it permanent, use **System Properties** > **Environment\n    Variables**.\n\n  </TabItem>\n\n  <TabItem label=\"Windows (PowerShell)\">\n    ```powershell\n    $env:EDITOR = \"notepad\"\n\n    # For GUI editors, VS Code, Cursor, VSCodium, Windsurf, Zed, etc.\n    # include --wait\n    $env:EDITOR = \"code --wait\"\n    ```\n\n    To make it permanent, add this to your PowerShell profile.\n\n  </TabItem>\n</Tabs>\n\nPopular editor options include:\n\n- `code` - Visual Studio Code\n- `cursor` - Cursor\n- `windsurf` - Windsurf\n- `vim` - Vim editor\n- `nano` - Nano editor\n- `notepad` - Windows Notepad\n- `subl` - Sublime Text\n\n:::note\nSome editors like VS Code need to be started with the `--wait` flag.\n:::\n\nSome editors need command-line arguments to run in blocking mode. The `--wait` flag makes the editor process block until closed.\n\n---\n\n## Configure\n\nYou can customize TUI behavior through your OpenCode config file.\n\n```json title=\"opencode.json\"\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"tui\": {\n    \"scroll_speed\": 3\n  }\n}\n```\n\n### Options\n\n- `scroll_speed` - Controls how fast the TUI scrolls when using scroll commands (default: `2`, minimum: `1`)","src/content/docs/tui.mdx","e07e4476235c7036","zen",{id:311,data:313,body:319,filePath:320,digest:321,deferredRender:16},{title:314,description:315,editUrl:16,head:316,template:18,sidebar:317,pagefind:16,draft:20},"Zen","Curated list of models provided by OpenCode.",[],{hidden:20,attrs:318},{},"import config from \"../../../config.mjs\"\nexport const console = config.console\nexport const email = `mailto:${config.email}`\n\nOpenCode Zen is a list of tested and verified models provided by the OpenCode team.\n\n:::note\nOpenCode Zen is currently in beta.\n:::\n\nZen works like any other provider in OpenCode. You login to OpenCode Zen and get\nyour API key. It's **completely optional** and you don't need to use it to use\nOpenCode.\n\n---\n\n## Background\n\nThere are a large number of models out there but only a few of\nthese models work well as coding agents. Additionally, most providers are\nconfigured very differently; so you get very different performance and quality.\n\n:::tip\nWe tested a select group of models and providers that work well with OpenCode.\n:::\n\nSo if you are using a model through something like OpenRouter, you can never be\nsure if you are getting the best version of the model you want.\n\nTo fix this, we did a couple of things:\n\n1. We tested a select group of models and talked to their teams about how to\n   best run them.\n2. We then worked with a few providers to make sure these were being served\n   correctly.\n3. Finally, we benchmarked the combination of the model/provider and came up\n   with a list that we feel good recommending.\n\nOpenCode Zen is an AI gateway that gives you access to these models.\n\n---\n\n## How it works\n\nOpenCode Zen works like any other provider in OpenCode.\n\n1. You sign in to **<a href={console}>OpenCode Zen</a>**, add your billing\n   details, and copy your API key.\n2. You run `opencode auth login`, select opencode, and paste your API key.\n3. Run `/models` in the TUI to see the list of models we recommend.\n\nYou are charged per request and you can add credits to your account.\n\n---\n\n## Endpoints\n\nYou can also access our models through the following API endpoints.\n\n| Model             | Model ID          | Endpoint                                      | AI SDK Package              |\n| ----------------- | ----------------- | --------------------------------------------- | --------------------------- |\n| GPT 5             | gpt-5             | `https://opencode.ai/zen/v1/responses`        | `@ai-sdk/openai`            |\n| GPT 5 Codex       | gpt-5-codex       | `https://opencode.ai/zen/v1/responses`        | `@ai-sdk/openai`            |\n| Claude Sonnet 4.5 | claude-sonnet-4-5 | `https://opencode.ai/zen/v1/messages`         | `@ai-sdk/anthropic`         |\n| Claude Sonnet 4   | claude-sonnet-4   | `https://opencode.ai/zen/v1/messages`         | `@ai-sdk/anthropic`         |\n| Claude Haiku 4.5  | claude-haiku-4-5  | `https://opencode.ai/zen/v1/messages`         | `@ai-sdk/anthropic`         |\n| Claude Haiku 3.5  | claude-3-5-haiku  | `https://opencode.ai/zen/v1/messages`         | `@ai-sdk/anthropic`         |\n| Claude Opus 4.1   | claude-opus-4-1   | `https://opencode.ai/zen/v1/messages`         | `@ai-sdk/anthropic`         |\n| Qwen3 Coder 480B  | qwen3-coder       | `https://opencode.ai/zen/v1/chat/completions` | `@ai-sdk/openai-compatible` |\n| Grok Code Fast 1  | grok-code         | `https://opencode.ai/zen/v1/chat/completions` | `@ai-sdk/openai-compatible` |\n| Kimi K2           | kimi-k2           | `https://opencode.ai/zen/v1/chat/completions` | `@ai-sdk/openai-compatible` |\n\nThe [model id](/docs/config/#models) in your OpenCode config\nuses the format `opencode/<model-id>`. For example, for GPT 5 Codex, you would\nuse `opencode/gpt-5-codex` in your config.\n\n---\n\n## Pricing\n\nWe support a pay-as-you-go model. Below are the prices **per 1M tokens**.\n\n| Model                             | Input  | Output | Cached Read | Cached Write |\n| --------------------------------- | ------ | ------ | ----------- | ------------ |\n| Qwen3 Coder 480B                  | $0.45  | $1.50  | -           | -            |\n| Kimi K2                           | $0.60  | $2.50  | $0.36       | -            |\n| Grok Code Fast 1                  | Free   | Free   | -           | -            |\n| Code Supernova                    | Free   | Free   | -           | -            |\n| Claude Sonnet 4.5 (≤ 200K tokens) | $3.00  | $15.00 | $0.30       | $3.75        |\n| Claude Sonnet 4.5 (> 200K tokens) | $6.00  | $22.50 | $0.60       | $7.50        |\n| Claude Sonnet 4 (≤ 200K tokens)   | $3.00  | $15.00 | $0.30       | $3.75        |\n| Claude Sonnet 4 (> 200K tokens)   | $6.00  | $22.50 | $0.60       | $7.50        |\n| Claude Haiku 4.5                  | $1.00  | $5.00  | $0.10       | $1.25        |\n| Claude Haiku 3.5                  | $0.80  | $4.00  | $0.08       | $1.00        |\n| Claude Opus 4.1                   | $15.00 | $75.00 | $1.50       | $18.75       |\n| GPT 5                             | $1.25  | $10.00 | $0.125      | -            |\n| GPT 5 Codex                       | $1.25  | $10.00 | $0.125      | -            |\n\nYou might notice _Claude Haiku 3.5_ in your usage history. This is a [low cost model](/docs/config/#models) that's used to generate the titles of your sessions.\n\n:::note\nCredit card fees are passed along at cost; we don't charge anything beyond that.\n:::\n\nThe free models:\n\n- Grok Code Fast 1 is currently free on OpenCode for a limited time. The xAI team is using this time to collect feedback and improve Grok Code.\n- Code Supernova is a stealth model that's free on OpenCode for a limited time. The team is using this time to collect feedback and improve the model.\n\n:::tip\nSubscription plans and a free tier are coming soon.\n:::\n\n<a href={email}>Contact us</a> if you have any questions.\n\n---\n\n## Privacy\n\nAll our models are hosted in the US. Our providers follow a zero-retention policy and do not use your data for model training, with the following exceptions:\n\n- Grok Code Fast 1: During its free period, collected data may be used to improve Grok Code.\n- Code Supernova: During its free period, collected data may be used to improve\n  the model.\n- OpenAI APIs: Requests are retained for 30 days in accordance with [OpenAI's Data Policies](https://platform.openai.com/docs/guides/your-data).\n- Anthropic APIs: Requests are retained for 30 days in accordance with [Anthropic's Data Policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).\n\n---\n\n## Goals\n\nWe created OpenCode Zen to:\n\n1. **Benchmark** the best models/providers for coding agents.\n2. Have access to the **highest quality** options and not downgrade performance or route to cheaper providers.\n3. Pass along any **price drops** by selling at cost; so the only markup is to cover our processing fees.\n4. Have **no lock-in** by allowing you to use it with any other coding agent. And always let you use any other provider with OpenCode as well.","src/content/docs/zen.mdx","0b508a13ae1379f9"];

export { _astro_dataLayerContent as default };
